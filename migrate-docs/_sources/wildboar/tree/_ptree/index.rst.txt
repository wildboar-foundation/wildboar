:orphan:

:py:mod:`wildboar.tree._ptree`
==============================

.. py:module:: wildboar.tree._ptree


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   wildboar.tree._ptree.ProximityTreeClassifier




.. py:class:: ProximityTreeClassifier(n_pivot=1, *, criterion='entropy', pivot_sample='label', metric_sample='weighted', metric='auto', metric_params=None, metric_factories=None, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_impurity_decrease=0.0, class_weight=None, random_state=None)

   Bases: :py:obj:`wildboar.tree.base.BaseTreeClassifier`

   A classifier that uses a k-branching tree based on pivot-time series.

   .. rubric:: Examples

   >>> from wildboar.datasets import load_dataset
   >>> from wildboar.tree import ProximityTreeClassifier
   >>> x, y = load_dataset("GunPoint")
   >>> f = ProximityTreeClassifier(
   ...     n_pivot=10,
   ...     metrics=[
   ...         ("dtw", {"min_r": 0.1, "max_r": 0.25}),
   ...         ("msm", {"min_c": 0.1, "max_c": 100, "num_c": 20})
   ...     ],
   ...     criterion="gini"
   ... )
   >>> f.fit(x, y)

   .. rubric:: References

   Lucas, Benjamin, Ahmed Shifaz, Charlotte Pelletier, Lachlan O'Neill, Nayyar Zaidi,     Bart Goethals, Fran√ßois Petitjean, and Geoffrey I. Webb. (2019)
       Proximity forest: an effective and scalable distance-based classifier for time
       series. Data Mining and Knowledge Discovery

   :param n_pivot: The number of pivots to sample at each node.
   :type n_pivot: int, optional
   :param criterion: The impurity criterion.
   :type criterion: {"entropy", "gini"}, optional
   :param pivot_sample: The pivot sampling method.
   :type pivot_sample: {"label", "uniform"}, optional
   :param metric_sample: The metric sampling method.
   :type metric_sample: {"uniform", "weighted"}, optional
   :param metric: The distance metrics. By default, we use the parameterization suggested by
                  Lucas et.al (2019).

                  - If str, use a single metric or default metric specification.

                  - If list A custom metric specification can be given as a list of tuples,
                    where the first element of the tuple is a metric name and the second
                    element a dictionary with a parameter grid specification. A parameter grid
                    specification is a dict with two mandatory and one optional key-value
                    pairs defining the lower and upper bound on the values as well as the
                    number of values in the grid. For example, to specifiy a grid over the
                    argument 'r' with 10 values in the range 0 to 1, we would give the
                    following specification: ``dict(min_r=0, max_r=1, num_r=10)``.

                  Read more about the metrics and their parameters in the
                  :ref:`User guide <list_of_metrics>`.
   :type metric: str or list, optional
   :param metric_params: Parameters for the distance measure. Ignored unless metric is a string.

                         Read more about the parameters in the :ref:`User guide
                         <list_of_metrics>`.
   :type metric_params: dict, optional
   :param max_depth: The maximum tree depth.
   :type max_depth: int, optional
   :param min_samples_split: The minimum number of samples to consider a split.
   :type min_samples_split: int, optional
   :param min_samples_leaf: The minimum number of samples in a leaf.
   :type min_samples_leaf: int, optional
   :param min_impurity_decrease: The minimum impurity decrease to build a sub-tree.
   :type min_impurity_decrease: float, optional
   :param class_weight: Weights associated with the labels.

                        - if dict, weights on the form {label: weight}.
                        - if "balanced" each class weight inversely proportional to the class
                          frequency.
                        - if None, each class has equal weight.
   :type class_weight: dict or "balanced", optional
   :param random_state:
                        - If `int`, `random_state` is the seed used by the random number generator
                        - If `RandomState` instance, `random_state` is the random number generator
                        - If `None`, the random number generator is the `RandomState` instance used
                          by `np.random`.
   :type random_state: int or RandomState


