:mod:`wildboar.model_selection.outlier`
=======================================

.. py:module:: wildboar.model_selection.outlier


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   wildboar.model_selection.outlier.RepeatedOutlierSplit



Functions
~~~~~~~~~

.. autoapisummary::

   wildboar.model_selection.outlier.train_test_split
   wildboar.model_selection.outlier.threshold_score


.. class:: RepeatedOutlierSplit(n_splits=None, *, test_size=0.2, n_outlier=0.05, shuffle=True, random_state=None)


   Repeated random outlier cross-validator

   Yields indicies that split the dataset into training and test sets.

   .. note::

      Contrary to other cross-validation strategies, the random outlier
      cross-validator does not ensure that all folds will be different.
      Instead, the inlier samples are shuffled and new outlier samples
      are inserted in the training and test sets repeatedly.

   .. method:: get_n_splits(self, X, y, groups=None)

      Returns the number of splitting iterations in the cross-validator
      :param X: The samples
      :type X: object
      :param y: The labels
      :type y: object
      :param groups: Always ignored, exists for compatibility.
      :type groups: object

      :returns: **n_splits** -- Returns the number of splitting iterations in the cross-validator.
      :rtype: int


   .. method:: split(self, x, y, groups=None)

      Return training and test indicies

      :param x: Always ignored, exists for compatibility.
      :type x: object
      :param y: The labels
      :type y: object
      :param groups: Always ignored, exists for compatibility.
      :type groups: object, optional

      :Yields: **train_idx, test_idx** (*ndarray*) -- The training and test indicies


   .. method:: __repr__(self)

      Return repr(self).



.. function:: train_test_split(x, y, normal_class, test_size=0.2, anomalies_train_size=0.05, random_state=None)

   Training and testing split from classification dataset

   :param x: Input data samples
   :type x: array-like of shape (n_samples, n_timestep) or (n_samples, n_dim, n_timestep)
   :param y: Input class label
   :type y: array-like of shape (n_samples,)
   :param normal_class: Class label that should be considered as the normal class
   :type normal_class: int
   :param test_size: Size of the test set
   :type test_size: float
   :param anomalies_train_size: Contamination of anomalies in the training dataset
   :type anomalies_train_size: float
   :param random_state: Psudo random state used for stable results.
   :type random_state: int or RandomState

   :returns: * **x_train** (*array-like*) -- Training samples
             * **x_test** (*array-like*) -- Test samples
             * **y_train** (*array-like*) -- Training labels (either 1 or -1, where 1 denotes normal and -1 anomalous)
             * **y_test** (*array-like*) -- Test labels (either 1 or -1, where 1 denotes normal and -1 anomalous)

   .. rubric:: Examples

   >>> from wildboar.datasets import load_two_lead_ecg
   >>> x, y = load_two_lead_ecg()
   >>> x_train, x_test, y_train, y_test = train_test_split(x, y, 1, test_size=0.2, anomalies_train_size=0.05)


.. function:: threshold_score(y_true, score, score_f)

   Compute the performance of using the i:th score

   The scores are typically computed using an outlier detection algorithm

   :param y_true: The true labels
   :type y_true: array-like
   :param score: The scores
   :type score: array-like
   :param score_f: Function for estimating the performance of the i:th scoring
   :type score_f: callable

   :returns: **score** -- performance for each score as threshold
   :rtype: ndarray

   .. seealso::

      :obj:`wildboar.ensemble.IsolationShapeletForest`
          an isolation forest for time series

   .. rubric:: Examples

   Setting the offset that maximizes balanced accuracy of a shapelet isolation forest

   >>> from wildboar.ensemble import IsolationShapeletForest
   >>> from wildboar.datasets import load_two_lead_ecg
   >>> from sklearn.metrics import balanced_accuracy_score
   >>> x, y = load_two_lead_ecg()
   >>> x_train, x_test, y_train, y_test = train_test_split(x, y, 1, test_size=0.2, anomalies_train_size=0.05)
   >>> f = IsolationShapeletForest()
   >>> f.fit(x_train)
   >>> scores = f.score_samples(x_train)
   >>> perf = threshold_score(y_train, scores, balanced_accuracy_score)
   >>> f.offset_ = score[np.argmax(perf)]


