:py:mod:`wildboar.transform`
============================

.. py:module:: wildboar.transform


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   catch22/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   base/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   wildboar.transform.FeatureTransform
   wildboar.transform.IntervalTransform
   wildboar.transform.MatrixProfileTransform
   wildboar.transform.PAA
   wildboar.transform.PivotTransform
   wildboar.transform.RandomShapeletTransform
   wildboar.transform.RocketTransform
   wildboar.transform.SAX



Functions
~~~~~~~~~

.. autoapisummary::

   wildboar.transform.piecewice_aggregate_approximation
   wildboar.transform.symbolic_aggregate_approximation



.. py:class:: FeatureTransform(*, summarizer='catch22', n_jobs=None)


   Bases: :py:obj:`IntervalTransform`

   Transform a time series as a number of features

   :param summarizer: The method to summarize each interval.

                      - if str, the summarizer is determined by `_SUMMARIZERS.keys()`.

                      - if list, the summarizer is a list of functions f(x) -> float, where
                        x is a numpy array.

                      The default summarizer summarizes each time series using catch22-features
   :type summarizer: str or list, optional
   :param n_jobs: The number of cores to use on multi-core.
   :type n_jobs: int, optional

   .. rubric:: References

   Lubba, Carl H., Sarab S. Sethi, Philip Knaute, Simon R. Schultz,         Ben D. Fulcher, and Nick S. Jones.
       catch22: Canonical time-series characteristics.
       Data Mining and Knowledge Discovery 33, no. 6 (2019): 1821-1852.


.. py:class:: IntervalTransform(n_intervals='sqrt', *, intervals='fixed', sample_size=0.5, min_size=0.0, max_size=1.0, summarizer='mean_var_slope', n_jobs=None, random_state=None)


   Bases: :py:obj:`wildboar.transform.base.BaseFeatureEngineerTransform`

   Embed a time series as a collection of features per interval.

   .. rubric:: Examples

   >>> from wildboar.datasets import load_dataset
   >>> x, y = load_dataset("GunPoint")
   >>> t = IntervalTransform(n_intervals=10, summarizer="mean")
   >>> t.fit_transform(x)

   Each interval (15 timepoints) are transformed to their mean.

   >>> t = IntervalTransform(n_intervals="sqrt", summarizer=[np.mean, np.std])
   >>> t.fit_transform(x)

   Each interval (150 // 12 timepoints) are transformed to two features. The mean
   and the standard deviation.

   :param n_intervals: The number of intervals to use for the transform.

                       - if "log", the number of intervals is ``log2(n_timestep)``.
                       - if "sqrt", the number of intervals is ``sqrt(n_timestep)``.
                       - if int, the number of intervals is ``n_intervals``.
                       - if float, the number of intervals is ``n_intervals * n_timestep``, with
                         ``0 < n_intervals < 1``.
   :type n_intervals: str, int or float, optional
   :param intervals: The method for selecting intervals

                     - if "fixed", `n_intervals` non-overlapping intervals.
                     - if "sample", ``n_intervals * sample_size`` non-overlapping intervals.
                     - if "random", `n_intervals` possibly overlapping intervals of randomly
                       sampled in ``[min_size * n_timestep, max_size * n_timestep]``
   :type intervals: str, optional
   :param sample_size: The sample size of fixed intervals if ``intervals="sample"``
   :type sample_size: float, optional
   :param min_size: The minimum interval size if ``intervals="random"``
   :type min_size: float, optional
   :param max_size: The maximum interval size if ``intervals="random"``
   :type max_size: float, optional
   :param summarizer: The method to summarize each interval.

                      - if str, the summarizer is determined by ``_SUMMARIZERS.keys()``.
                      - if list, the summarizer is a list of functions ``f(x) -> float``, where
                        x is a numpy array.

                      The default summarizer summarizes each interval as its mean, standard
                      deviation and slope.
   :type summarizer: str or list, optional
   :param n_jobs: The number of cores to use on multi-core.
   :type n_jobs: int, optional
   :param random_state:
                        - If `int`, `random_state` is the seed used by the random number generator
                        - If `RandomState` instance, `random_state` is the random number generator
                        - If `None`, the random number generator is the `RandomState` instance used
                          by `np.random`.
   :type random_state: int or RandomState


.. py:class:: MatrixProfileTransform(window=0.1, exclude=None, n_jobs=None)


   Bases: :py:obj:`sklearn.base.TransformerMixin`, :py:obj:`wildboar.base.BaseEstimator`

   Transform each time series in a dataset to its MatrixProfile similarity self-join

   .. rubric:: Examples

   >>> from wildboar.datasets import load_two_lead_ecg()
   >>> from wildboar.transform import MatrixProfileTransform
   >>> x, y = load_two_lead_ecg()
   >>> t = MatrixProfileTransform()
   >>> t.fit_transform(x)

   :param window:
   :type window: int or float, optional
   :param The subsequence size:
   :param by default 0.1:
   :param - if float:
   :param a fraction of n_timestep:
   :param - if int:
   :param the exact subsequence size:
   :param exclude: The size of the exclusion zone. The default exclusion zone is 0.2

                   - if float, expressed as a fraction of the windows size
                   - if int, exact size (0 < exclude)
   :type exclude: int or float, optional
   :param n_jobs: The number of jobs to use when computing the
   :type n_jobs: int, optional

   .. py:method:: fit(x, y=None)

      Fit the matrix profile. Sets the expected input dimensions

      :param x: The samples
      :type x: array-like of shape (n_samples, n_timesteps)         or (n_samples, n_dims, n_timesteps)
      :param y: The optional labels.
      :type y: ignored

      :returns: **self**
      :rtype: a fitted instance


   .. py:method:: transform(x)

      Transform the samples to their MatrixProfile self-join.

      :param x: The samples
      :type x: array-like of shape (n_samples, n_timesteps)         or (n_samples, n_dims, n_timesteps)

      :returns: **mp** -- The matrix matrix profile of each sample
      :rtype: ndarray of shape (n_samples, n_timestep)         or (n_samples, n_dims, n_timesteps)



.. py:class:: PAA(n_intervals='sqrt', window=None)


   Bases: :py:obj:`sklearn.base.TransformerMixin`, :py:obj:`wildboar.base.BaseEstimator`

   Peicewise aggregate approximation

   .. py:property:: intervals


   .. py:method:: fit(x, y=None)


   .. py:method:: inverse_transform(x)


   .. py:method:: transform(x)



.. py:class:: PivotTransform(n_pivots=1, *, metric_factories=None, random_state=None, n_jobs=None)


   Bases: :py:obj:`wildboar.transform.base.BaseFeatureEngineerTransform`

   A transform using pivot time series and sampled distance metrics.

   :param metric_factories: The distance metrics. A dictionary where key is:

                            - if str, a named distance factory (See ``_DISTANCE_FACTORIES.keys()``)
                            - if callable, a function returning a list of ``DistanceMeasure``-objects

                            and where value is a dict of parameters to the factory.
   :type metric_factories: dict, optional


.. py:class:: RandomShapeletTransform(n_shapelets=1000, *, metric='euclidean', metric_params=None, min_shapelet_size=0, max_shapelet_size=1.0, n_jobs=None, random_state=None)


   Bases: :py:obj:`wildboar.transform.base.BaseFeatureEngineerTransform`

   Transform a time series to the distances to a selection of random shapelets.

   .. attribute:: embedding_

      The underlying embedding object.

      :type: Embedding

   .. rubric:: References

   Wistuba, Martin, Josif Grabocka, and Lars Schmidt-Thieme.
       Ultra-fast shapelets for time series classification.
       arXiv preprint arXiv:1503.05018 (2015).

   :param n_shapelets: The number of shapelets in the resulting transform
   :type n_shapelets: int, optional
   :param metric: Distance metric used to identify the best shapelet.

                  See ``distance._SUBSEQUENCE_DISTANCE_MEASURE.keys()`` for a list of
                  supported metrics.
   :type metric: str, optional
   :param metric_params: Parameters for the distance measure.

                         Read more about the parameters in the
                         :ref:`User guide <list_of_subsequence_metrics>`.
   :type metric_params: dict, optional
   :param min_shapelet_size: Minimum shapelet size.
   :type min_shapelet_size: float, optional
   :param max_shapelet_size: Maximum shapelet size.
   :type max_shapelet_size: float, optional
   :param n_jobs: The number of jobs to run in parallel. None means 1 and
                  -1 means using all processors.
   :type n_jobs: int, optional
   :param random_state: The psudo-random number generator.
   :type random_state: int or RandomState, optional


.. py:class:: RocketTransform(n_kernels=1000, *, sampling='normal', sampling_params=None, kernel_size=None, bias_prob=1.0, normalize_prob=1.0, padding_prob=0.5, n_jobs=None, random_state=None)


   Bases: :py:obj:`wildboar.transform.base.BaseFeatureEngineerTransform`

   Transform a time series using random convolution features

   .. attribute:: embedding_

      The underlying embedding

      :type: Embedding

   .. rubric:: References

   Dempster, Angus, Fran√ßois Petitjean, and Geoffrey I. Webb.
       ROCKET: exceptionally fast and accurate time series classification using
       random convolutional kernels.
       Data Mining and Knowledge Discovery 34.5 (2020): 1454-1495.

   :param n_kernels: The number of kernels.
   :type n_kernels: int, optional
   :param n_jobs: The number of jobs to run in parallel. None means 1 and
                  -1 means using all processors.
   :type n_jobs: int, optional
   :param random_state: The psuodo-random number generator.
   :type random_state: int or RandomState, optional


.. py:class:: SAX(*, n_intervals='sqrt', window=None, n_bins=4, binning='normal', estimate=True)


   Bases: :py:obj:`sklearn.base.TransformerMixin`, :py:obj:`wildboar.base.BaseEstimator`

   Symbolic aggregate approximation

   :param x: The input data.
   :type x: array-like of shape (n_samples, n_timestep)
   :param n_intervals: The number of intervals to use for the transform.

                       - if "log", the number of intervals is ``log2(n_timestep)``.
                       - if "sqrt", the number of intervals is ``sqrt(n_timestep)``.
                       - if int, the number of intervals is ``n_intervals``.
                       - if float, the number of intervals is ``n_intervals * n_timestep``, with
                           ``0 < n_intervals < 1``.
   :type n_intervals: str, optional
   :param window: The window size. If ``window`` is set, the value of ``n_intervals`` has no
                  effect.
   :type window: int, optional
   :param n_bins: The number of bins.
   :type n_bins: int, optional
   :param binning: The bin construction. By default the bins are defined according to the
                   normal distribution. Possible values are ``"normal"`` for normally
                   distributed bins or ``"uniform"`` for uniformly distributed bins.
   :type binning: str, optional
   :param estimate: Estimate the distribution parameters for the binning from data.

                    If ``estimate=False``, it is assumed that each time series are:

                    - preprocessed using :func:`datasets.preprocess.normalize` when
                      ``binning="normal"``.

                    - preprocessed using :func:`datasets.preprocess.minmax_scale`. when
                      ``binning="uniform"``
   :type estimate: bool, optional

   .. py:property:: intervals


   .. py:method:: fit(x, y=None)


   .. py:method:: inverse_transform(x)


   .. py:method:: transform(x)



.. py:function:: piecewice_aggregate_approximation(x, *, n_intervals='sqrt', window=None)

   Peicewise aggregate approximation

   :param x: The input data.
   :type x: array-like of shape (n_samples, n_timestep)
   :param n_intervals: The number of intervals to use for the transform.

                       - if "log", the number of intervals is ``log2(n_timestep)``.
                       - if "sqrt", the number of intervals is ``sqrt(n_timestep)``.
                       - if int, the number of intervals is ``n_intervals``.
                       - if float, the number of intervals is ``n_intervals * n_timestep``, with
                           ``0 < n_intervals < 1``.
   :type n_intervals: str, optional
   :param window: The window size. If ``window`` is set, the value of ``n_intervals`` has no
                  effect.
   :type window: int, optional

   :returns: **paa** -- The symbolic aggregate approximation
   :rtype: ndarray of shape (n_samples, n_intervals)


.. py:function:: symbolic_aggregate_approximation(x, *, n_intervals='sqrt', window=None, n_bins=4, binning='normal')

   Symbolic aggregate approximation

   :param x: The input data.
   :type x: array-like of shape (n_samples, n_timestep)
   :param n_intervals: The number of intervals to use for the transform.

                       - if "log", the number of intervals is ``log2(n_timestep)``.
                       - if "sqrt", the number of intervals is ``sqrt(n_timestep)``.
                       - if int, the number of intervals is ``n_intervals``.
                       - if float, the number of intervals is ``n_intervals * n_timestep``, with
                           ``0 < n_intervals < 1``.
   :type n_intervals: str, optional
   :param window: The window size. If ``window`` is set, the value of ``n_intervals`` has no
                  effect.
   :type window: int, optional
   :param n_bins: The number of bins.
   :type n_bins: int, optional
   :param binning: The bin construction. By default the bins are defined according to the
                   normal distribution. Possible values are ``"normal"`` for normally
                   distributed bins or ``"uniform"`` for uniformly distributed bins.
   :type binning: str, optional

   :returns: **sax** -- The symbolic aggregate approximation
   :rtype: ndarray of shape (n_samples, n_intervals)


