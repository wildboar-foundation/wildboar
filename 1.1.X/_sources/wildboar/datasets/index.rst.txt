:py:mod:`wildboar.datasets`
===========================

.. py:module:: wildboar.datasets


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   filter/index.rst
   outlier/index.rst
   preprocess/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   wildboar.datasets.Bundle
   wildboar.datasets.JSONRepository
   wildboar.datasets.NpBundle
   wildboar.datasets.Repository



Functions
~~~~~~~~~

.. autoapisummary::

   wildboar.datasets.clear_cache
   wildboar.datasets.get_bundles
   wildboar.datasets.get_repository
   wildboar.datasets.install_repository
   wildboar.datasets.list_bundles
   wildboar.datasets.list_collections
   wildboar.datasets.list_datasets
   wildboar.datasets.list_repositories
   wildboar.datasets.load_dataset
   wildboar.datasets.load_datasets
   wildboar.datasets.load_gun_point
   wildboar.datasets.load_synthetic_control
   wildboar.datasets.load_two_lead_ecg
   wildboar.datasets.refresh_repositories
   wildboar.datasets.set_cache_dir



.. py:class:: Bundle(*, key, version, name, tag=None, arrays=None, description=None, collections=None)

   Base class for handling dataset bundles

   .. attribute:: name

      Human-readable name of the bundle

      :type: str

   .. attribute:: description

      Description of the bundle

      :type: str

   .. attribute:: label_index

      Index of the class label(s)

      :type: int or array-like

   :param key: A unique key of the bundle
   :type key: str
   :param version: The version of the bundle
   :type version: str
   :param name: Human-readable name of the bundle
   :type name: str
   :param description: Description of the bundle
   :type description: str
   :param arrays: The arrays of the dataset
   :type arrays: list

   .. py:method:: get_collection(collection)


   .. py:method:: get_filename(version=None, tag=None, ext=None)


   .. py:method:: list(archive, collection=None)

      List all datasets in this bundle

      :param archive: The bundle file
      :type archive: ZipFile
      :param collection: The collection name
      :type collection: str, optional

      :returns: **dataset_names** -- A sorted list of datasets in the bundle
      :rtype: list


   .. py:method:: load(name, archive)

      Load a dataset from the bundle

      :param name: Name of the dataset
      :type name: str
      :param archive: The zip-file bundle
      :type archive: ZipFile

      :returns: * **x** (*ndarray*) -- Data samples
                * **y** (*ndarray*) -- Data labels
                * **n_training_samples** (*int*) -- Number of samples that are for training. The value is <= x.shape[0]
                * **extras** (*dict, optional*) -- Extra numpy arrays



.. py:class:: JSONRepository(url)

   Bases: :py:obj:`Repository`

   A repository is a collection of bundles

   .. py:property:: download_url

      The url template for downloading bundles

      :returns: **str**
      :rtype: the download url

   .. py:property:: identifier


   .. py:property:: name

      Name of the repository

      :returns: **str**
      :rtype: the name of the repository

   .. py:property:: version

      The repository version

      :returns: **str**
      :rtype: the version of the repository

   .. py:property:: wildboar_requires

      The minimum required wildboar version

      :returns: **str**
      :rtype: the min version

   .. py:attribute:: supported_version
      :annotation: = 1.1

      

   .. py:method:: get_bundles()

      Get all bundles

      :returns: **dict**
      :rtype: a dictionary of key and bundle



.. py:class:: NpBundle(*, key, version, name, tag=None, arrays=None, description=None, collections=None)

   Bases: :py:obj:`Bundle`

   bundle of numpy binary files

   :param key: A unique key of the bundle
   :type key: str
   :param version: The version of the bundle
   :type version: str
   :param name: Human-readable name of the bundle
   :type name: str
   :param description: Description of the bundle
   :type description: str
   :param arrays: The arrays of the dataset
   :type arrays: list


.. py:class:: Repository

   A repository is a collection of bundles

   .. py:property:: active


   .. py:property:: download_url
      :abstractmethod:

      The url template for downloading bundles

      :returns: **str**
      :rtype: the download url

   .. py:property:: identifier
      :abstractmethod:


   .. py:property:: name
      :abstractmethod:

      Name of the repository

      :returns: **str**
      :rtype: the name of the repository

   .. py:property:: version
      :abstractmethod:

      The repository version

      :returns: **str**
      :rtype: the version of the repository

   .. py:property:: wildboar_requires
      :abstractmethod:

      The minimum required wildboar version

      :returns: **str**
      :rtype: the min version

   .. py:method:: __eq__(o)

      Return self==value.


   .. py:method:: __hash__() -> int

      Return hash(self).


   .. py:method:: clear_cache(cache_dir, keep_last_version=True)


   .. py:method:: get_bundle(key)

      Get a bundle with the specified key

      :param key: Key of the bundle
      :type key: str

      :returns: **bundle** -- A bundle or None
      :rtype: Bundle, optional


   .. py:method:: get_bundles()
      :abstractmethod:

      Get all bundles

      :returns: **dict**
      :rtype: a dictionary of key and bundle


   .. py:method:: list_datasets(bundle, *, cache_dir, collection=None, version=None, tag=None, create_cache_dir=True, progress=True, force=False)


   .. py:method:: load_dataset(bundle, dataset, *, cache_dir, version=None, tag=None, create_cache_dir=True, progress=True, force=False)


   .. py:method:: refresh(timeout=None)

      Refresh the repository



.. py:function:: clear_cache(repository=None, *, cache_dir=None, keep_last_version=True)

   Clear the cache by deleting cached datasets

   :param repository: The name of the repository to clear cache.

                      - if None, clear cache of all repositories
   :type repository: str, optional
   :param cache_dir: The cache directory
   :type cache_dir: str, optional
   :param keep_last_version: If true, keep the latest version of each repository.
   :type keep_last_version: bool, optional


.. py:function:: get_bundles(repository, *, refresh=False, timeout=None)

   Get all bundles in the repository

   :param repository: Name of the repository
   :type repository: str
   :param refresh: Refresh the repository

                   ..versionadded :: 1.1
   :type refresh: bool, optional
   :param timeout: Timeout for json request

                   ..versionadded :: 1.1
   :type timeout: float, optional

   :returns: **dict**
   :rtype: A dict of key Bundle pairs


.. py:function:: get_repository(repository)

   Get repository by name

   :param repository: Repository name
   :type repository: str

   :returns: **repository** -- A repository
   :rtype: Repository


.. py:function:: install_repository(repository, *, refresh=True, timeout=None, cache_dir=None)

   Install repository

   :param repository: A repository
   :type repository: str or Repository
   :param refresh: Refresh the repository

                   ..versionadded :: 1.1
   :type refresh: bool, optional
   :param timeout: Timeout for json request

                   ..versionadded :: 1.1
   :type timeout: float, optional
   :param cache_dir: Cache directory

                     ..versionadded :: 1.1
   :type cache_dir: str, optional


.. py:function:: list_bundles(repository, *, refresh=False, timeout=None)

   Get a list of all bundle names in the specified repository.

   :param repository: The name of the repository
   :type repository: str
   :param refresh: Refresh the repository

                   ..versionadded :: 1.1
   :type refresh: bool, optional
   :param timeout: Timeout for json request

                   ..versionadded :: 1.1
   :type timeout: float, optional

   :returns: **bundle** -- The name of the bundle
   :rtype: str


.. py:function:: list_collections(repository)

   List the collections of the repository

   :param repository: The data repository

                      - if str load a named bundle, format {repository}/{bundle}
   :type repository: str or Bundle, optional

   :returns: **list**
   :rtype: a list of collections


.. py:function:: list_datasets(repository='wildboar/ucr', *, collection=None, cache_dir=None, create_cache_dir=True, progress=True, force=False, refresh=False, timeout=None)

   List the datasets in the repository

   :param repository: The data repository

                      - if str load a named bundle, format {repository}/{bundle}
   :type repository: str or Bundle, optional
   :param collection: A collection of named datasets.
   :type collection: str, optional
   :param progress: Show a progress bar while downloading a bundle.
   :type progress: bool, optional
   :param cache_dir: The directory where downloaded files are cached (default='wildboar_cache')
   :type cache_dir: str, optional
   :param create_cache_dir: Create cache directory if missing (default=True)
   :type create_cache_dir: bool, optional
   :param force: Force re-download of cached bundle
   :type force: bool, optional
   :param refresh: Refresh the repository

                   .. versionadded :: 1.1
   :type refresh: bool, optional
   :param timeout: Timeout for json request

                   .. versionadded :: 1.1
   :type timeout: float, optional

   :returns: **dataset** -- A set of dataset names
   :rtype: set


.. py:function:: list_repositories(*, refresh=False, timeout=None, cache_dir=None)

   List the key of all installed repositories

   refresh : bool, optional
       Refresh all repositories

       ..versionadded :: 1.1

   timeout : float, optional
       Timeout for json request

       ..versionadded :: 1.1

   cache_dir : str, optional
       Cache directory

       ..versionadded :: 1.1


.. py:function:: load_dataset(name, *, repository='wildboar/ucr', dtype=float, preprocess=None, contiguous=True, merge_train_test=True, cache_dir=None, create_cache_dir=True, progress=True, return_extras=False, force=False, refresh=False, timeout=None)

   Load a dataset from a repository

   :param name: The name of the dataset to load.
   :type name: str
   :param repository: The data repository formatted as {repository}/{bundle}[:{version}][:{tag}]
   :type repository: str, optional
   :param dtype: The data type of x (train and test)
   :type dtype: dtype, optional
   :param contiguous: Ensure that the returned dataset is memory contiguous.
   :type contiguous: bool, optional
   :param preprocess: Preprocess the dataset

                      - if str, use named preprocess function (see ``preprocess._PREPROCESS.keys()``
                        for valid keys)
                      - if callable, function taking a np.ndarray and returns the preprocessed dataset
                      - if list, a list of callable or str
   :type preprocess: str, list or callable, optional
   :param merge_train_test: Merge the existing training and testing partitions.
   :type merge_train_test: bool, optional
   :param progress: Show a progress bar while downloading a bundle.
   :type progress: bool, optional
   :param cache_dir: The directory where downloaded files are cached
   :type cache_dir: str, optional
   :param create_cache_dir: Create cache directory if missing (default=True)
   :type create_cache_dir: bool, optional
   :param return_extras: Return optional extras

                         .. versionadded :: 1.1
   :type return_extras: bool, optional
   :param force: Force re-download of already cached bundle

                 .. versionadded :: 1.0.4
   :type force: bool, optional
   :param refresh: Refresh the repository

                   .. versionadded :: 1.1
   :type refresh: bool, optional
   :param timeout: Timeout for json request

                   .. versionadded :: 1.1
   :type timeout: float, optional

   :returns: * **x** (*ndarray*) -- The data samples, optional
             * **y** (*ndarray, optional*) -- The labels
             * **x_train** (*ndarray, optional*) -- The training samples if ``merge_train_test=False``
             * **x_test** (*ndarray, optional*) -- The testing samples if ``merge_train_test=False``
             * **y_train** (*ndarray, optional*) -- The training labels if ``merge_train_test=False``
             * **y_test** (*ndarray, optional*) -- The testing labels if ``merge_train_test=False``
             * **extras** (*dict, optional*) -- The optional extras if ``return_extras=True``

   .. rubric:: Examples

   Load a dataset from the default repository

   >>> x, y = load_dataset("SyntheticControl")

   or if original training and testing splits are to be preserved

   >>> x_train, x_test, y_train, y_test = load_dataset(
   ...     "SyntheticControl", merge_train_test=False
   ... )

   or for a specific version of the dataset

   >>> x_train, x_test, y_train, y_test = load_dataset(
   ...     "Wafer", repository='wildboar/ucr-tiny:1.0'
   ... )


.. py:function:: load_datasets(repository='wildboar/ucr', *, collection=None, cache_dir=None, create_cache_dir=True, progress=True, force=False, filter=None, **kwargs)

   Load all datasets as a generator

   :param repository: The repository string
   :type repository: str
   :param collection: A collection of named datasets.
   :type collection: str, optional
   :param progress: If progress indicator is shown while downloading the repository.
   :type progress: bool, optional
   :param cache_dir: The cache directory for downloaded dataset repositories.
   :type cache_dir: str, optional
   :param create_cache_dir: Create the cache directory if it does not exist.
   :type create_cache_dir: bool, optional
   :param force: Force re-download of cached repository
   :type force: bool, optional
   :param filter: Filter the datasets

                  - if callable, only yield those datasets for which the callable returns True.
                    ``f(dataset, x, y) -> bool``

                  - if dict, filter based on the keys and values, where keys are attributes and
                    values comparison specs

                  - if list, filter based on conjunction of attribute comparisons

                  - if str, filter based on attribute comparison

                  The format of attribute comparisons are ``[attribute][comparison spec]``.

                  Valid attributes are
                  - ``dataset``
                  - ``n_samples``
                  - ``n_timestep``
                  - ``n_dims``
                  - ``n_labels``

                  The `comparison spec` is a string of two parts, comparison operator
                  (<, <=, >, >= or =) and a number, e.g., "<100", "<= 200", or ">300"
   :type filter: str, dict, list or callable, optional
   :param kwargs: Optional arguments to ``load_dataset``
   :type kwargs: dict

   :Yields: * **x** (*array-like*) -- Data samples
            * **y** (*array-like*) -- Data labels

   .. rubric:: Examples

   >>> from wildboar.datasets import load_datasets
   >>> for dataset, (x, y) in load_datasets(repository='wildboar/ucr'):
   >>>     print(dataset, x.shape, y.shape)

   Print the names of datasets with more than 200 samples

   >>> for dataset, (x, y) in load_datasets(
   ...    repository='wildboar/ucr', filter={"n_samples": ">200"}
   ... ):
   >>>     print(dataset)

   >>> for dataset, (x, y) in load_datasets(
   ...    repository='wildboar/ucr', filter="n_samples>200"
   ... ):
   >>>     print(dataset)


.. py:function:: load_gun_point(merge_train_test=True)

   Load the GunPoint dataset

   .. seealso::

      :obj:`load_dataset`
          load a named dataset


.. py:function:: load_synthetic_control(merge_train_test=True)

   Load the Synthetic_Control dataset

   .. seealso::

      :obj:`load_dataset`
          load a named dataset


.. py:function:: load_two_lead_ecg(merge_train_test=True)

   Load the TwoLeadECG dataset

   .. seealso::

      :obj:`load_dataset`
          load a named dataset


.. py:function:: refresh_repositories(repository=None, *, timeout=None, cache_dir=None)

   Refresh the installed repositories

   repository : str, optional
       The repository. None means all repositories.

   timeout : float, optional
       Timeout for request

       ..versionadded :: 1.1

   cache_dir : str, optional
       Cache directory

       ..versionadded :: 1.1


.. py:function:: set_cache_dir(cache_dir=None)

   Change the global cache directory. If called without arguments, the cache
   directory is reset to the default directory.

   cache_dir : str, optional
       The cache directory root


