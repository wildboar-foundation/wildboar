<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <meta name="generator" content="sphinx-5.2.2, furo 2022.09.15"/>
        <title>wildboar.ensemble._ensemble - Wildboar 1.1.0rc4 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?digest=9ec31e2665bf879c1d47d93a8ec4893870ee1e45" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    


    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">Wildboar 1.1.0rc4 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><div class="sidebar-scroll"><a class="sidebar-brand" href="../../../index.html">
    
    <div class="sidebar-logo-container">
        <img class="sidebar-logo only-light" src="../../../_static/logo.png" alt="Light Logo" />
        <img class="sidebar-logo only-dark" src="../../../_static/logo.png" alt="Dark Logo" />
    </div>
    
    <span class="sidebar-brand-text">Wildboar
        <small>1.1.0rc4</small></span>
    
</a><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installing wildboar</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial.html">wildboar tutorial</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../guide.html">User guide</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/basics.html">Time series</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/datasets.html">Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/supervised.html">Supervised learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/unsupervised.html">Unsupervised learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/metrics.html">Distance metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/explain.html">Explainability</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../examples.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/annotate.html">Annotate</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/annotate/motif.html">Motif discovery</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/annotate/segment.html">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/distance.html">Distance</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/distance/distance.html">Pairwise and paired distance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/distance/distance-benchmark.html">Distance benchmarks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/distance/dtw.html">Dynamic time warping</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/embeddings.html">Embeddings</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/embedding/interval.html">Interval</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/embedding/rocket.html">Rocket</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/embedding/shapelet.html">Shapelets</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/explainability.html">Explainability</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/explainability/counterfactuals.html">Comparing counterfactals</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/supervised.html">Supervised</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/supervised/classifier_comparision.html">Comparing classifiers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/supervised/miss_classification_analysis.html">Miss-classification analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/supervised/shapelet_forest_vs_shapelet_extra_trees.html">Shapelet forests and extremly randomized shapelet trees</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/unsupervised.html">Unsupervised</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/unsupervised/matrix_profile.html">Matrix profile</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/notebooks/unsupervised/outlier_detection.html">Outlier detection</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../more.html">More</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../more/whatsnew.html">What’s new</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../more/versions/v1.1.html">Version 1.1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../more/versions/v1.0.html">Version 1.0</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../more/versions/older.html">Older versions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../more/contributing.html">Developer’s guide</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../index.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../annotate/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.annotate</span></code></a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../datasets/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.datasets</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../datasets/filter/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.datasets.filter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../datasets/outlier/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.datasets.outlier</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../datasets/preprocess/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.datasets.preprocess</span></code></a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../distance/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.distance</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../distance/dtw/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.distance.dtw</span></code></a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../embed/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.embed</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../embed/catch22/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.embed.catch22</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../embed/base/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.embed.base</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.ensemble</span></code></a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../explain/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.explain</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../explain/counterfactual/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.explain.counterfactual</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../explain/counterfactual/base/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.explain.counterfactual.base</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../explain/base/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.explain.base</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../linear_model/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.linear_model</span></code></a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../model_selection/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.model_selection</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_selection/outlier/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.model_selection.outlier</span></code></a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../tree/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.tree</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../tree/base/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.tree.base</span></code></a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../utils/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.utils</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../utils/decorators/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.utils.decorators</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../utils/plot/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.utils.plot</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../version/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.version</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
<div class="sidebar-tree">
    <ul>
        <li class="toctree-l1 has-children"><a class="reference internal" href="#">Versions</a>
            <input class="toctree-checkbox" id="version-checkbox-1" name="version-checkbox-1" type="checkbox"><label
                for="version-checkbox-1"><i class="icon"><svg>
                        <use href="#svg-arrow-right"></use>
                    </svg></i></label>
            <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../../master/index.html">1.1.0rc5</a></li>
                <li class="toctree-l2"><a class="reference internal" href="../../../../1.0.X/index.html">1.0.12</a></li>
                <li class="toctree-l2"><span class="reference internal">1.1.0rc4</span></li>
            </ul>
        </li>
    </ul>
</div></div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="module-wildboar.ensemble._ensemble">
<span id="wildboar-ensemble-ensemble"></span><h1><a class="reference internal" href="#module-wildboar.ensemble._ensemble" title="wildboar.ensemble._ensemble"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.ensemble._ensemble</span></code></a><a class="headerlink" href="#module-wildboar.ensemble._ensemble" title="Permalink to this heading">#</a></h1>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Permalink to this heading">#</a></h2>
<section id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this heading">#</a></h3>
<div class="table-wrapper autosummary longtable docutils container">
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier" title="wildboar.ensemble._ensemble.BaseForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseForestClassifier</span></code></a></p></td>
<td><p>A Bagging classifier.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor" title="wildboar.ensemble._ensemble.BaseForestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseForestRegressor</span></code></a></p></td>
<td><p>A Bagging regressor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseShapeletForestClassifier" title="wildboar.ensemble._ensemble.BaseShapeletForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseShapeletForestClassifier</span></code></a></p></td>
<td><p>Base class for shapelet forest classifiers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseShapeletForestRegressor" title="wildboar.ensemble._ensemble.BaseShapeletForestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseShapeletForestRegressor</span></code></a></p></td>
<td><p>Base class for shapelet forest classifiers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.ExtraShapeletTreesClassifier" title="wildboar.ensemble._ensemble.ExtraShapeletTreesClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExtraShapeletTreesClassifier</span></code></a></p></td>
<td><p>An ensemble of extremely random shapelet trees for time series regression.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.ExtraShapeletTreesRegressor" title="wildboar.ensemble._ensemble.ExtraShapeletTreesRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExtraShapeletTreesRegressor</span></code></a></p></td>
<td><p>An ensemble of extremely random shapelet trees for time series regression.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.ForestMixin" title="wildboar.ensemble._ensemble.ForestMixin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ForestMixin</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier" title="wildboar.ensemble._ensemble.IntervalForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">IntervalForestClassifier</span></code></a></p></td>
<td><p>A Bagging classifier.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor" title="wildboar.ensemble._ensemble.IntervalForestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">IntervalForestRegressor</span></code></a></p></td>
<td><p>A Bagging regressor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest" title="wildboar.ensemble._ensemble.IsolationShapeletForest"><code class="xref py py-obj docutils literal notranslate"><span class="pre">IsolationShapeletForest</span></code></a></p></td>
<td><p>A isolation shapelet forest.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier" title="wildboar.ensemble._ensemble.PivotForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PivotForestClassifier</span></code></a></p></td>
<td><p>A Bagging classifier.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.ProximityForestClassifier" title="wildboar.ensemble._ensemble.ProximityForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ProximityForestClassifier</span></code></a></p></td>
<td><p>A forest of proximity trees</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier" title="wildboar.ensemble._ensemble.RockestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RockestClassifier</span></code></a></p></td>
<td><p>A Bagging classifier.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor" title="wildboar.ensemble._ensemble.RockestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RockestRegressor</span></code></a></p></td>
<td><p>A Bagging regressor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestClassifier" title="wildboar.ensemble._ensemble.ShapeletForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ShapeletForestClassifier</span></code></a></p></td>
<td><p>An ensemble of random shapelet tree classifiers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding" title="wildboar.ensemble._ensemble.ShapeletForestEmbedding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ShapeletForestEmbedding</span></code></a></p></td>
<td><p>An ensemble of random shapelet trees</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestRegressor" title="wildboar.ensemble._ensemble.ShapeletForestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ShapeletForestRegressor</span></code></a></p></td>
<td><p>An ensemble of random shapelet regression trees.</p></td>
</tr>
</tbody>
</table>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">BaseForestClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">tuple()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'entropy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L171-L222"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.ForestMixin" title="wildboar.ensemble._ensemble.ForestMixin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ForestMixin</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.ensemble.BaggingClassifier</span></code></p>
<p>A Bagging classifier.</p>
<p>A Bagging classifier is an ensemble meta-estimator that fits base
classifiers each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.</p>
<p>This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting <a href="#id57"><span class="problematic" id="id1">[1]_</span></a>. If samples are drawn with
replacement, then the method is known as Bagging <a href="#id58"><span class="problematic" id="id2">[2]_</span></a>. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces <a href="#id59"><span class="problematic" id="id3">[3]_</span></a>. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches <a href="#id60"><span class="problematic" id="id4">[4]_</span></a>.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.15.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_estimator</strong> (<em>object</em><em>, </em><em>default=None</em>) – The base estimator to fit on random subsets of the dataset.
If None, then the base estimator is a
<code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code>.</p></li>
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>default=10</em>) – The number of base estimators in the ensemble.</p></li>
<li><p><strong>max_samples</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of samples to draw from X to train each base estimator (with
replacement by default, see <cite>bootstrap</cite> for more details).</p>
<ul>
<li><p>If int, then draw <cite>max_samples</cite> samples.</p></li>
<li><p>If float, then draw <cite>max_samples * X.shape[0]</cite> samples.</p></li>
</ul>
</p></li>
<li><p><strong>max_features</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of features to draw from X to train each base estimator (
without replacement by default, see <cite>bootstrap_features</cite> for more
details).</p>
<ul>
<li><p>If int, then draw <cite>max_features</cite> features.</p></li>
<li><p>If float, then draw <cite>max(1, int(max_features * n_features_in_))</cite> features.</p></li>
</ul>
</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Whether samples are drawn with replacement. If False, sampling
without replacement is performed.</p></li>
<li><p><strong>bootstrap_features</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether features are drawn with replacement.</p></li>
<li><p><strong>oob_score</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to use out-of-bag samples to estimate
the generalization error. Only available if bootstrap=True.</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble. See <span class="xref std std-term">the Glossary</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17: </span><em>warm_start</em> constructor parameter.</p>
</div>
</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of jobs to run in parallel for both <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.fit" title="wildboar.ensemble._ensemble.BaseForestClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> and
<a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.predict" title="wildboar.ensemble._ensemble.BaseForestClassifier.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>. <code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a
<code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all
processors. See <span class="xref std std-term">Glossary</span> for more details.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the random resampling of the original dataset
(sample wise and feature wise).
If the base estimator accepts a <cite>random_state</cite> attribute, a different
seed is generated for each instance in the ensemble.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – Controls the verbosity when fitting and predicting.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.base_estimator_">
<span class="sig-name descname"><span class="pre">base_estimator_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.base_estimator_" title="Permalink to this definition">#</a></dt>
<dd><p>The base estimator from which the ensemble is grown.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>estimator</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.n_features_">
<span class="sig-name descname"><span class="pre">n_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.n_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The number of features when <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.fit" title="wildboar.ensemble._ensemble.BaseForestClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> is performed.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.0: </span>Attribute <cite>n_features_</cite> was deprecated in version 1.0 and will be
removed in 1.2. Use <cite>n_features_in_</cite> instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.n_features_in_">
<span class="sig-name descname"><span class="pre">n_features_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.n_features_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Number of features seen during <span class="xref std std-term">fit</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.feature_names_in_">
<span class="sig-name descname"><span class="pre">feature_names_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.feature_names_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Names of features seen during <span class="xref std std-term">fit</span>. Defined only when <cite>X</cite>
has feature names that are all strings.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (<cite>n_features_in_</cite>,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.estimators_">
<span class="sig-name descname"><span class="pre">estimators_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.estimators_" title="Permalink to this definition">#</a></dt>
<dd><p>The collection of fitted base estimators.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of estimators</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.estimators_samples_">
<span class="sig-name descname"><span class="pre">estimators_samples_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.estimators_samples_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn samples (i.e., the in-bag samples) for each base
estimator. Each subset is defined by an array of the indices selected.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.estimators_features_">
<span class="sig-name descname"><span class="pre">estimators_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.estimators_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn features for each base estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.classes_">
<span class="sig-name descname"><span class="pre">classes_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.classes_" title="Permalink to this definition">#</a></dt>
<dd><p>The classes labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_classes,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.n_classes_">
<span class="sig-name descname"><span class="pre">n_classes_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.n_classes_" title="Permalink to this definition">#</a></dt>
<dd><p>The number of classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int or list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.oob_score_">
<span class="sig-name descname"><span class="pre">oob_score_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.oob_score_" title="Permalink to this definition">#</a></dt>
<dd><p>Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.oob_decision_function_">
<span class="sig-name descname"><span class="pre">oob_decision_function_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.oob_decision_function_" title="Permalink to this definition">#</a></dt>
<dd><p>Decision function computed with out-of-bag estimate on the training
set. If n_estimators is small it might be possible that a data point
was never left out during the bootstrap. In this case,
<cite>oob_decision_function_</cite> might contain NaN. This attribute exists
only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_classes)</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaggingRegressor</span></code></dt><dd><p>A Bagging regressor.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id5" role="note">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Pasting small votes for classification in large
databases and on-line”, Machine Learning, 36(1), 85-103, 1999.</p>
</aside>
<aside class="footnote brackets" id="id6" role="note">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140,
1996.</p>
</aside>
<aside class="footnote brackets" id="id7" role="note">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>T. Ho, “The random subspace method for constructing decision
forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844,
1998.</p>
</aside>
<aside class="footnote brackets" id="id8" role="note">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine
Learning and Knowledge Discovery in Databases, 346-361, 2012.</p>
</aside>
</aside>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">SVC</span><span class="p">(),</span>
<span class="gp">... </span>                        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="go">array([1])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_input</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L155-L168"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.fit" title="Permalink to this definition">#</a></dt>
<dd><p>Build a Bagging ensemble of estimators from the training set (X, y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p></li>
<li><p><strong>y</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The target values (class labels in classification, real numbers in
regression).</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights. If None, then samples are equally weighted.
Note that this is supported only if the base estimator supports
sample weighting.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>self</strong> – Fitted estimator.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.predict" title="Permalink to this definition">#</a></dt>
<dd><p>Predict class for X.</p>
<p>The predicted class of an input sample is computed as the class with
the highest mean predicted probability. If base estimators do not
implement a <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> method, then it resorts to voting.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>y</strong> – The predicted classes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.predict_log_proba">
<span class="sig-name descname"><span class="pre">predict_log_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.predict_log_proba" title="Permalink to this definition">#</a></dt>
<dd><p>Predict class log-probabilities for X.</p>
<p>The predicted class log-probabilities of an input sample is computed as
the log of the mean predicted class probabilities of the base
estimators in the ensemble.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>p</strong> – The class log-probabilities of the input samples. The order of the
classes corresponds to that in the attribute <span class="xref std std-term">classes_</span>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_classes)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestClassifier.predict_proba" title="Permalink to this definition">#</a></dt>
<dd><p>Predict class probabilities for X.</p>
<p>The predicted class probabilities of an input sample is computed as
the mean predicted class probabilities of the base estimators in the
ensemble. If base estimators do not implement a <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>
method, then it resorts to voting and the predicted class probabilities
of an input sample represents the proportion of estimators predicting
each class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>p</strong> – The class probabilities of the input samples. The order of the
classes corresponds to that in the attribute <span class="xref std std-term">classes_</span>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_classes)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">BaseForestRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">tuple()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L593-L640"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestRegressor" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.ForestMixin" title="wildboar.ensemble._ensemble.ForestMixin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ForestMixin</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.ensemble.BaggingRegressor</span></code></p>
<p>A Bagging regressor.</p>
<p>A Bagging regressor is an ensemble meta-estimator that fits base
regressors each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.</p>
<p>This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting <a href="#id61"><span class="problematic" id="id9">[1]_</span></a>. If samples are drawn with
replacement, then the method is known as Bagging <a href="#id62"><span class="problematic" id="id10">[2]_</span></a>. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces <a href="#id63"><span class="problematic" id="id11">[3]_</span></a>. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches <a href="#id64"><span class="problematic" id="id12">[4]_</span></a>.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.15.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_estimator</strong> (<em>object</em><em>, </em><em>default=None</em>) – The base estimator to fit on random subsets of the dataset.
If None, then the base estimator is a
<code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code>.</p></li>
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>default=10</em>) – The number of base estimators in the ensemble.</p></li>
<li><p><strong>max_samples</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of samples to draw from X to train each base estimator (with
replacement by default, see <cite>bootstrap</cite> for more details).</p>
<ul>
<li><p>If int, then draw <cite>max_samples</cite> samples.</p></li>
<li><p>If float, then draw <cite>max_samples * X.shape[0]</cite> samples.</p></li>
</ul>
</p></li>
<li><p><strong>max_features</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of features to draw from X to train each base estimator (
without replacement by default, see <cite>bootstrap_features</cite> for more
details).</p>
<ul>
<li><p>If int, then draw <cite>max_features</cite> features.</p></li>
<li><p>If float, then draw <cite>max(1, int(max_features * n_features_in_))</cite> features.</p></li>
</ul>
</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Whether samples are drawn with replacement. If False, sampling
without replacement is performed.</p></li>
<li><p><strong>bootstrap_features</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether features are drawn with replacement.</p></li>
<li><p><strong>oob_score</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to use out-of-bag samples to estimate
the generalization error. Only available if bootstrap=True.</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>default=False</em>) – When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble. See <span class="xref std std-term">the Glossary</span>.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of jobs to run in parallel for both <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.fit" title="wildboar.ensemble._ensemble.BaseForestRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> and
<code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code>. <code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a
<code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all
processors. See <span class="xref std std-term">Glossary</span> for more details.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the random resampling of the original dataset
(sample wise and feature wise).
If the base estimator accepts a <cite>random_state</cite> attribute, a different
seed is generated for each instance in the ensemble.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – Controls the verbosity when fitting and predicting.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestRegressor.base_estimator_">
<span class="sig-name descname"><span class="pre">base_estimator_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestRegressor.base_estimator_" title="Permalink to this definition">#</a></dt>
<dd><p>The base estimator from which the ensemble is grown.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>estimator</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestRegressor.n_features_">
<span class="sig-name descname"><span class="pre">n_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestRegressor.n_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The number of features when <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.fit" title="wildboar.ensemble._ensemble.BaseForestRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> is performed.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.0: </span>Attribute <cite>n_features_</cite> was deprecated in version 1.0 and will be
removed in 1.2. Use <cite>n_features_in_</cite> instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestRegressor.n_features_in_">
<span class="sig-name descname"><span class="pre">n_features_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestRegressor.n_features_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Number of features seen during <span class="xref std std-term">fit</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestRegressor.feature_names_in_">
<span class="sig-name descname"><span class="pre">feature_names_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestRegressor.feature_names_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Names of features seen during <span class="xref std std-term">fit</span>. Defined only when <cite>X</cite>
has feature names that are all strings.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (<cite>n_features_in_</cite>,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestRegressor.estimators_">
<span class="sig-name descname"><span class="pre">estimators_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestRegressor.estimators_" title="Permalink to this definition">#</a></dt>
<dd><p>The collection of fitted sub-estimators.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of estimators</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestRegressor.estimators_samples_">
<span class="sig-name descname"><span class="pre">estimators_samples_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestRegressor.estimators_samples_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn samples (i.e., the in-bag samples) for each base
estimator. Each subset is defined by an array of the indices selected.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestRegressor.estimators_features_">
<span class="sig-name descname"><span class="pre">estimators_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestRegressor.estimators_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn features for each base estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestRegressor.oob_score_">
<span class="sig-name descname"><span class="pre">oob_score_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestRegressor.oob_score_" title="Permalink to this definition">#</a></dt>
<dd><p>Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestRegressor.oob_prediction_">
<span class="sig-name descname"><span class="pre">oob_prediction_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestRegressor.oob_prediction_" title="Permalink to this definition">#</a></dt>
<dd><p>Prediction computed with out-of-bag estimate on the training
set. If n_estimators is small it might be possible that a data point
was never left out during the bootstrap. In this case,
<cite>oob_prediction_</cite> might contain NaN. This attribute exists only
when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaggingClassifier</span></code></dt><dd><p>A Bagging classifier.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id13" role="note">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Pasting small votes for classification in large
databases and on-line”, Machine Learning, 36(1), 85-103, 1999.</p>
</aside>
<aside class="footnote brackets" id="id14" role="note">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140,
1996.</p>
</aside>
<aside class="footnote brackets" id="id15" role="note">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>T. Ho, “The random subspace method for constructing decision
forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844,
1998.</p>
</aside>
<aside class="footnote brackets" id="id16" role="note">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine
Learning and Knowledge Discovery in Databases, 346-361, 2012.</p>
</aside>
</aside>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_targets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span> <span class="o">=</span> <span class="n">BaggingRegressor</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">SVR</span><span class="p">(),</span>
<span class="gp">... </span>                        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="go">array([-2.8720...])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseForestRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_input</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L586-L590"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseForestRegressor.fit" title="Permalink to this definition">#</a></dt>
<dd><p>Build a Bagging ensemble of estimators from the training set (X, y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p></li>
<li><p><strong>y</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The target values (class labels in classification, real numbers in
regression).</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights. If None, then samples are equally weighted.
Note that this is supported only if the base estimator supports
sample weighting.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>self</strong> – Fitted estimator.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseShapeletForestClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">BaseShapeletForestClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">tuple()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_shapelets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'entropy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L225-L277"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseShapeletForestClassifier" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier" title="wildboar.ensemble._ensemble.BaseForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseForestClassifier</span></code></a></p>
<p>Base class for shapelet forest classifiers.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This class should not be used directly. Use derived classes
instead.</p>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.BaseShapeletForestRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">BaseShapeletForestRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_estimator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">tuple()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_shapelets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L643-L696"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.BaseShapeletForestRegressor" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor" title="wildboar.ensemble._ensemble.BaseForestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseForestRegressor</span></code></a></p>
<p>Base class for shapelet forest classifiers.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This class should not be used directly. Use derived classes
instead.</p>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.ExtraShapeletTreesClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">ExtraShapeletTreesClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'entropy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L435-L557"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.ExtraShapeletTreesClassifier" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseShapeletForestClassifier" title="wildboar.ensemble._ensemble.BaseShapeletForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseShapeletForestClassifier</span></code></a></p>
<p>An ensemble of extremely random shapelet trees for time series regression.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.ensemble</span> <span class="kn">import</span> <span class="n">ExtraShapeletTreesClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.datasets</span> <span class="kn">import</span> <span class="n">load_synthetic_control</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_synthetic_control</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">ExtraShapeletTreesClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;scaled_euclidean&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Construct a extra shapelet trees classifier.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of estimators</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use bootstrap sampling to fit the base estimators</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of processor cores used for fitting the ensemble</p></li>
<li><p><strong>min_shapelet_size</strong> (<em>float</em><em>, </em><em>optional</em>) – The minimum shapelet size to sample</p></li>
<li><p><strong>max_shapelet_size</strong> (<em>float</em><em>, </em><em>optional</em>) – The maximum shapelet size to sample</p></li>
<li><p><strong>min_samples_split</strong> (<em>int</em><em>, </em><em>optional</em>) – The minimum samples required to split the decision trees</p></li>
<li><p><strong>min_samples_leaf</strong> (<em>int</em><em>, </em><em>optional</em>) – The minimum number of samples in a leaf</p></li>
<li><p><strong>criterion</strong> (<em>{&quot;entropy&quot;</em><em>, </em><em>&quot;gini&quot;}</em><em>, </em><em>optional</em>) – The criterion used to evaluate the utility of a split</p></li>
<li><p><strong>min_impurity_decrease</strong> (<em>float</em><em>, </em><em>optional</em>) – A split will be introduced only if the impurity decrease is larger than or
equal to this value</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble.</p></li>
<li><p><strong>metric</strong> (<em>{'euclidean'</em><em>, </em><em>'scaled_euclidean'</em><em>, </em><em>'scaled_dtw'}</em><em>, </em><em>optional</em>) – Set the metric used to compute the distance between shapelet and time series</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – Parameters passed to the metric construction</p></li>
<li><p><strong>class_weight</strong> (<em>dict</em><em> or </em><em>&quot;balanced&quot;</em><em>, </em><em>optional</em>) – <p>Weights associated with the labels</p>
<ul>
<li><p>if dict, weights on the form {label: weight}</p></li>
<li><p>if “balanced” each class weight inversely proportional to the class
frequency</p></li>
<li><p>if None, each class has equal weight</p></li>
</ul>
</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>RandomState</em><em>, </em><em>optional</em>) – Controls the random resampling of the original dataset and the construction
of the base estimators. Pass an int for reproducible output across multiple
function calls.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.ExtraShapeletTreesRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">ExtraShapeletTreesRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L833-L931"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.ExtraShapeletTreesRegressor" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseShapeletForestRegressor" title="wildboar.ensemble._ensemble.BaseShapeletForestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseShapeletForestRegressor</span></code></a></p>
<p>An ensemble of extremely random shapelet trees for time series regression.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.ensemble</span> <span class="kn">import</span> <span class="n">ExtraShapeletTreesRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.datasets</span> <span class="kn">import</span> <span class="n">load_synthetic_control</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_synthetic_control</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">ExtraShapeletTreesRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;scaled_euclidean&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Construct a extra shapelet trees regressor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of estimators</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use bootstrap sampling to fit the base estimators</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of processor cores used for fitting the ensemble</p></li>
<li><p><strong>min_shapelet_size</strong> (<em>float</em><em>, </em><em>optional</em>) – The minimum shapelet size to sample</p></li>
<li><p><strong>max_shapelet_size</strong> (<em>float</em><em>, </em><em>optional</em>) – The maximum shapelet size to sample</p></li>
<li><p><strong>min_samples_split</strong> (<em>int</em><em>, </em><em>optional</em>) – The minimum samples required to split the decision trees</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble.</p></li>
<li><p><strong>metric</strong> (<em>{'euclidean'</em><em>, </em><em>'scaled_euclidean'</em><em>, </em><em>'scaled_dtw'}</em><em>, </em><em>optional</em>) – Set the metric used to compute the distance between shapelet and time series</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – Parameters passed to the metric construction</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>RandomState</em><em>, </em><em>optional</em>) – Controls the random resampling of the original dataset and the construction
of the base estimators. Pass an int for reproducible output across multiple
function calls.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.ForestMixin">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">ForestMixin</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L95-L123"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.ForestMixin" title="Permalink to this definition">#</a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.ForestMixin.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L96-L105"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.ForestMixin.apply" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.ForestMixin.decision_path">
<span class="sig-name descname"><span class="pre">decision_path</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L107-L123"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.ForestMixin.decision_path" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">IntervalForestClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sqrt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intervals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'fixed'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summarizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'entropy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1517-L1578"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestClassifier" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier" title="wildboar.ensemble._ensemble.BaseForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseForestClassifier</span></code></a></p>
<p>A Bagging classifier.</p>
<p>A Bagging classifier is an ensemble meta-estimator that fits base
classifiers each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.</p>
<p>This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting <a href="#id65"><span class="problematic" id="id17">[1]_</span></a>. If samples are drawn with
replacement, then the method is known as Bagging <a href="#id66"><span class="problematic" id="id18">[2]_</span></a>. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces <a href="#id67"><span class="problematic" id="id19">[3]_</span></a>. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches <a href="#id68"><span class="problematic" id="id20">[4]_</span></a>.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.15.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_estimator</strong> (<em>object</em><em>, </em><em>default=None</em>) – The base estimator to fit on random subsets of the dataset.
If None, then the base estimator is a
<code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code>.</p></li>
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>default=10</em>) – The number of base estimators in the ensemble.</p></li>
<li><p><strong>max_samples</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of samples to draw from X to train each base estimator (with
replacement by default, see <cite>bootstrap</cite> for more details).</p>
<ul>
<li><p>If int, then draw <cite>max_samples</cite> samples.</p></li>
<li><p>If float, then draw <cite>max_samples * X.shape[0]</cite> samples.</p></li>
</ul>
</p></li>
<li><p><strong>max_features</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of features to draw from X to train each base estimator (
without replacement by default, see <cite>bootstrap_features</cite> for more
details).</p>
<ul>
<li><p>If int, then draw <cite>max_features</cite> features.</p></li>
<li><p>If float, then draw <cite>max(1, int(max_features * n_features_in_))</cite> features.</p></li>
</ul>
</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Whether samples are drawn with replacement. If False, sampling
without replacement is performed.</p></li>
<li><p><strong>bootstrap_features</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether features are drawn with replacement.</p></li>
<li><p><strong>oob_score</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to use out-of-bag samples to estimate
the generalization error. Only available if bootstrap=True.</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble. See <span class="xref std std-term">the Glossary</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17: </span><em>warm_start</em> constructor parameter.</p>
</div>
</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of jobs to run in parallel for both <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> and
<code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code>. <code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a
<code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all
processors. See <span class="xref std std-term">Glossary</span> for more details.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the random resampling of the original dataset
(sample wise and feature wise).
If the base estimator accepts a <cite>random_state</cite> attribute, a different
seed is generated for each instance in the ensemble.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – Controls the verbosity when fitting and predicting.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestClassifier.base_estimator_">
<span class="sig-name descname"><span class="pre">base_estimator_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.base_estimator_" title="Permalink to this definition">#</a></dt>
<dd><p>The base estimator from which the ensemble is grown.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>estimator</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestClassifier.n_features_">
<span class="sig-name descname"><span class="pre">n_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.n_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The number of features when <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> is performed.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.0: </span>Attribute <cite>n_features_</cite> was deprecated in version 1.0 and will be
removed in 1.2. Use <cite>n_features_in_</cite> instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestClassifier.n_features_in_">
<span class="sig-name descname"><span class="pre">n_features_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.n_features_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Number of features seen during <span class="xref std std-term">fit</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestClassifier.feature_names_in_">
<span class="sig-name descname"><span class="pre">feature_names_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.feature_names_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Names of features seen during <span class="xref std std-term">fit</span>. Defined only when <cite>X</cite>
has feature names that are all strings.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (<cite>n_features_in_</cite>,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestClassifier.estimators_">
<span class="sig-name descname"><span class="pre">estimators_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.estimators_" title="Permalink to this definition">#</a></dt>
<dd><p>The collection of fitted base estimators.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of estimators</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestClassifier.estimators_samples_">
<span class="sig-name descname"><span class="pre">estimators_samples_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.estimators_samples_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn samples (i.e., the in-bag samples) for each base
estimator. Each subset is defined by an array of the indices selected.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestClassifier.estimators_features_">
<span class="sig-name descname"><span class="pre">estimators_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.estimators_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn features for each base estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestClassifier.classes_">
<span class="sig-name descname"><span class="pre">classes_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.classes_" title="Permalink to this definition">#</a></dt>
<dd><p>The classes labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_classes,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestClassifier.n_classes_">
<span class="sig-name descname"><span class="pre">n_classes_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.n_classes_" title="Permalink to this definition">#</a></dt>
<dd><p>The number of classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int or list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestClassifier.oob_score_">
<span class="sig-name descname"><span class="pre">oob_score_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.oob_score_" title="Permalink to this definition">#</a></dt>
<dd><p>Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestClassifier.oob_decision_function_">
<span class="sig-name descname"><span class="pre">oob_decision_function_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.oob_decision_function_" title="Permalink to this definition">#</a></dt>
<dd><p>Decision function computed with out-of-bag estimate on the training
set. If n_estimators is small it might be possible that a data point
was never left out during the bootstrap. In this case,
<cite>oob_decision_function_</cite> might contain NaN. This attribute exists
only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_classes)</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaggingRegressor</span></code></dt><dd><p>A Bagging regressor.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id21" role="note">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Pasting small votes for classification in large
databases and on-line”, Machine Learning, 36(1), 85-103, 1999.</p>
</aside>
<aside class="footnote brackets" id="id22" role="note">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140,
1996.</p>
</aside>
<aside class="footnote brackets" id="id23" role="note">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>T. Ho, “The random subspace method for constructing decision
forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844,
1998.</p>
</aside>
<aside class="footnote brackets" id="id24" role="note">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine
Learning and Knowledge Discovery in Databases, 346-361, 2012.</p>
</aside>
</aside>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">SVC</span><span class="p">(),</span>
<span class="gp">... </span>                        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="go">array([1])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">IntervalForestRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sqrt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intervals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'fixed'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summarizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1581-L1640"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestRegressor" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor" title="wildboar.ensemble._ensemble.BaseForestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseForestRegressor</span></code></a></p>
<p>A Bagging regressor.</p>
<p>A Bagging regressor is an ensemble meta-estimator that fits base
regressors each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.</p>
<p>This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting <a href="#id69"><span class="problematic" id="id25">[1]_</span></a>. If samples are drawn with
replacement, then the method is known as Bagging <a href="#id70"><span class="problematic" id="id26">[2]_</span></a>. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces <a href="#id71"><span class="problematic" id="id27">[3]_</span></a>. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches <a href="#id72"><span class="problematic" id="id28">[4]_</span></a>.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.15.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_estimator</strong> (<em>object</em><em>, </em><em>default=None</em>) – The base estimator to fit on random subsets of the dataset.
If None, then the base estimator is a
<code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code>.</p></li>
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>default=10</em>) – The number of base estimators in the ensemble.</p></li>
<li><p><strong>max_samples</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of samples to draw from X to train each base estimator (with
replacement by default, see <cite>bootstrap</cite> for more details).</p>
<ul>
<li><p>If int, then draw <cite>max_samples</cite> samples.</p></li>
<li><p>If float, then draw <cite>max_samples * X.shape[0]</cite> samples.</p></li>
</ul>
</p></li>
<li><p><strong>max_features</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of features to draw from X to train each base estimator (
without replacement by default, see <cite>bootstrap_features</cite> for more
details).</p>
<ul>
<li><p>If int, then draw <cite>max_features</cite> features.</p></li>
<li><p>If float, then draw <cite>max(1, int(max_features * n_features_in_))</cite> features.</p></li>
</ul>
</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Whether samples are drawn with replacement. If False, sampling
without replacement is performed.</p></li>
<li><p><strong>bootstrap_features</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether features are drawn with replacement.</p></li>
<li><p><strong>oob_score</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to use out-of-bag samples to estimate
the generalization error. Only available if bootstrap=True.</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>default=False</em>) – When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble. See <span class="xref std std-term">the Glossary</span>.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of jobs to run in parallel for both <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> and
<code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code>. <code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a
<code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all
processors. See <span class="xref std std-term">Glossary</span> for more details.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the random resampling of the original dataset
(sample wise and feature wise).
If the base estimator accepts a <cite>random_state</cite> attribute, a different
seed is generated for each instance in the ensemble.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – Controls the verbosity when fitting and predicting.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestRegressor.base_estimator_">
<span class="sig-name descname"><span class="pre">base_estimator_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.base_estimator_" title="Permalink to this definition">#</a></dt>
<dd><p>The base estimator from which the ensemble is grown.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>estimator</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestRegressor.n_features_">
<span class="sig-name descname"><span class="pre">n_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.n_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The number of features when <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> is performed.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.0: </span>Attribute <cite>n_features_</cite> was deprecated in version 1.0 and will be
removed in 1.2. Use <cite>n_features_in_</cite> instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestRegressor.n_features_in_">
<span class="sig-name descname"><span class="pre">n_features_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.n_features_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Number of features seen during <span class="xref std std-term">fit</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestRegressor.feature_names_in_">
<span class="sig-name descname"><span class="pre">feature_names_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.feature_names_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Names of features seen during <span class="xref std std-term">fit</span>. Defined only when <cite>X</cite>
has feature names that are all strings.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (<cite>n_features_in_</cite>,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestRegressor.estimators_">
<span class="sig-name descname"><span class="pre">estimators_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.estimators_" title="Permalink to this definition">#</a></dt>
<dd><p>The collection of fitted sub-estimators.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of estimators</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestRegressor.estimators_samples_">
<span class="sig-name descname"><span class="pre">estimators_samples_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.estimators_samples_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn samples (i.e., the in-bag samples) for each base
estimator. Each subset is defined by an array of the indices selected.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestRegressor.estimators_features_">
<span class="sig-name descname"><span class="pre">estimators_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.estimators_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn features for each base estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestRegressor.oob_score_">
<span class="sig-name descname"><span class="pre">oob_score_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.oob_score_" title="Permalink to this definition">#</a></dt>
<dd><p>Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IntervalForestRegressor.oob_prediction_">
<span class="sig-name descname"><span class="pre">oob_prediction_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.oob_prediction_" title="Permalink to this definition">#</a></dt>
<dd><p>Prediction computed with out-of-bag estimate on the training
set. If n_estimators is small it might be possible that a data point
was never left out during the bootstrap. In this case,
<cite>oob_prediction_</cite> might contain NaN. This attribute exists only
when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaggingClassifier</span></code></dt><dd><p>A Bagging classifier.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id29" role="note">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Pasting small votes for classification in large
databases and on-line”, Machine Learning, 36(1), 85-103, 1999.</p>
</aside>
<aside class="footnote brackets" id="id30" role="note">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140,
1996.</p>
</aside>
<aside class="footnote brackets" id="id31" role="note">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>T. Ho, “The random subspace method for constructing decision
forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844,
1998.</p>
</aside>
<aside class="footnote brackets" id="id32" role="note">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine
Learning and Knowledge Discovery in Databases, 346-361, 2012.</p>
</aside>
</aside>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_targets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span> <span class="o">=</span> <span class="n">BaggingRegressor</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">SVR</span><span class="p">(),</span>
<span class="gp">... </span>                        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="go">array([-2.8720...])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IsolationShapeletForest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">IsolationShapeletForest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contamination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contamination_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'training'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1064-L1340"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IsolationShapeletForest" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.ForestMixin" title="wildboar.ensemble._ensemble.ForestMixin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ForestMixin</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.base.OutlierMixin</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.ensemble._bagging.BaseBagging</span></code></p>
<p>A isolation shapelet forest.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.3.5.</span></p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IsolationShapeletForest.offset_">
<span class="sig-name descname"><span class="pre">offset_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.offset_" title="Permalink to this definition">#</a></dt>
<dd><p>The offset for computing the final decision</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.ensemble</span> <span class="kn">import</span> <span class="n">IsolationShapeletForest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.datasets</span> <span class="kn">import</span> <span class="n">load_two_lead_ecg</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.model_selection.outlier</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">balanced_accuracy_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_two_lead_ecg</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="gp">... </span>   <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">anomalies_train_size</span><span class="o">=</span><span class="mf">0.05</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">IsolationShapeletForest</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="n">balanced_accuracy_score</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
<p>Or using default offset threshold</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.ensemble</span> <span class="kn">import</span> <span class="n">IsolationShapeletForest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.datasets</span> <span class="kn">import</span> <span class="n">load_two_lead_ecg</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.model_selection.outlier</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">balanced_accuracy_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">IsolationShapeletForest</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_two_lead_ecg</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">anomalies_train_size</span><span class="o">=</span><span class="mf">0.05</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
<p>Construct a shapelet isolation forest</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of estimators</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use bootstrap sampling to fit the base estimators</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of processor cores used for fitting the ensemble</p></li>
<li><p><strong>min_shapelet_size</strong> (<em>float</em><em>, </em><em>optional</em>) – The minimum shapelet size to sample</p></li>
<li><p><strong>max_shapelet_size</strong> (<em>float</em><em>, </em><em>optional</em>) – The maximum shapelet size to sample</p></li>
<li><p><strong>min_samples_split</strong> (<em>int</em><em>, </em><em>optional</em>) – The minimum samples required to split the decision trees</p></li>
<li><p><strong>max_samples</strong> (<em>float</em><em> or </em><em>int</em>) – The number of samples to draw to train each base estimator</p></li>
<li><p><strong>contamination</strong> (<em>str</em><em>, </em><em>float</em><em> or </em><em>callable</em>) – <p>The strategy for computing the offset (see <cite>offset_</cite>)</p>
<ul>
<li><p>if ‘auto’ <code class="docutils literal notranslate"><span class="pre">offset_=-0.5</span></code></p></li>
<li><p>if ‘auc’ <code class="docutils literal notranslate"><span class="pre">offset_</span></code> is computed as the offset that maximizes the
area under ROC in the training or out-of-bag set
(see <code class="docutils literal notranslate"><span class="pre">contamination_set</span></code>).</p></li>
<li><p>if ‘prc’ <code class="docutils literal notranslate"><span class="pre">offset_</span></code> is computed as the offset that maximizes the
area under PRC in the training or out-of-bag set
(see <code class="docutils literal notranslate"><span class="pre">contamination_set</span></code>)</p></li>
<li><p>if callable <code class="docutils literal notranslate"><span class="pre">offset_</span></code> is computed as the offset that maximizes the score
computed by the callable in training or out-of-bag set
(see <code class="docutils literal notranslate"><span class="pre">contamination_set</span></code>)</p></li>
<li><p>if float <code class="docutils literal notranslate"><span class="pre">offset_</span></code> is computed as the c:th percentile of scores in the
training or out-of-bag set (see <code class="docutils literal notranslate"><span class="pre">contamination_set</span></code>)</p></li>
</ul>
<p>Setting contamination to either ‘auc’ or ‘prc’ require that <cite>y</cite> is passed
to <cite>fit</cite>.</p>
</p></li>
<li><p><strong>contamination_set</strong> (<em>{'training'</em><em>, </em><em>'oob'}</em><em>, </em><em>optional</em>) – Compute the <code class="docutils literal notranslate"><span class="pre">offset_</span></code> from either the out-of-bag samples or the training
samples.’oob’ require <cite>bootstrap=True</cite>.</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble.</p></li>
<li><p><strong>metric</strong> (<em>{'euclidean'</em><em>, </em><em>'scaled_euclidean'</em><em>, </em><em>'scaled_dtw'}</em><em>, </em><em>optional</em>) – Set the metric used to compute the distance between shapelet and time series</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – Parameters passed to the metric construction</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>RandomState</em><em>, </em><em>optional</em>) – Controls the random resampling of the original dataset and the construction
of the base estimators. Pass an int for reproducible output across multiple
function calls.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IsolationShapeletForest.decision_function">
<span class="sig-name descname"><span class="pre">decision_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1318-L1319"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.decision_function" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IsolationShapeletForest.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_input</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1221-L1311"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.fit" title="Permalink to this definition">#</a></dt>
<dd><p>Build a Bagging ensemble of estimators from the training set (X, y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p></li>
<li><p><strong>y</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The target values (class labels in classification, real numbers in
regression).</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights. If None, then samples are equally weighted.
Note that this is supported only if the base estimator supports
sample weighting.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>self</strong> – Fitted estimator.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IsolationShapeletForest.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1313-L1316"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.predict" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.IsolationShapeletForest.score_samples">
<span class="sig-name descname"><span class="pre">score_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1321-L1324"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.score_samples" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.PivotForestClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">PivotForestClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_pivot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sqrt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'entropy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1643-L1692"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.PivotForestClassifier" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier" title="wildboar.ensemble._ensemble.BaseForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseForestClassifier</span></code></a></p>
<p>A Bagging classifier.</p>
<p>A Bagging classifier is an ensemble meta-estimator that fits base
classifiers each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.</p>
<p>This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting <a href="#id73"><span class="problematic" id="id33">[1]_</span></a>. If samples are drawn with
replacement, then the method is known as Bagging <a href="#id74"><span class="problematic" id="id34">[2]_</span></a>. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces <a href="#id75"><span class="problematic" id="id35">[3]_</span></a>. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches <a href="#id76"><span class="problematic" id="id36">[4]_</span></a>.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.15.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_estimator</strong> (<em>object</em><em>, </em><em>default=None</em>) – The base estimator to fit on random subsets of the dataset.
If None, then the base estimator is a
<code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code>.</p></li>
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>default=10</em>) – The number of base estimators in the ensemble.</p></li>
<li><p><strong>max_samples</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of samples to draw from X to train each base estimator (with
replacement by default, see <cite>bootstrap</cite> for more details).</p>
<ul>
<li><p>If int, then draw <cite>max_samples</cite> samples.</p></li>
<li><p>If float, then draw <cite>max_samples * X.shape[0]</cite> samples.</p></li>
</ul>
</p></li>
<li><p><strong>max_features</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of features to draw from X to train each base estimator (
without replacement by default, see <cite>bootstrap_features</cite> for more
details).</p>
<ul>
<li><p>If int, then draw <cite>max_features</cite> features.</p></li>
<li><p>If float, then draw <cite>max(1, int(max_features * n_features_in_))</cite> features.</p></li>
</ul>
</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Whether samples are drawn with replacement. If False, sampling
without replacement is performed.</p></li>
<li><p><strong>bootstrap_features</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether features are drawn with replacement.</p></li>
<li><p><strong>oob_score</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to use out-of-bag samples to estimate
the generalization error. Only available if bootstrap=True.</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble. See <span class="xref std std-term">the Glossary</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17: </span><em>warm_start</em> constructor parameter.</p>
</div>
</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of jobs to run in parallel for both <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> and
<code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code>. <code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a
<code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all
processors. See <span class="xref std std-term">Glossary</span> for more details.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the random resampling of the original dataset
(sample wise and feature wise).
If the base estimator accepts a <cite>random_state</cite> attribute, a different
seed is generated for each instance in the ensemble.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – Controls the verbosity when fitting and predicting.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.PivotForestClassifier.base_estimator_">
<span class="sig-name descname"><span class="pre">base_estimator_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.PivotForestClassifier.base_estimator_" title="Permalink to this definition">#</a></dt>
<dd><p>The base estimator from which the ensemble is grown.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>estimator</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.PivotForestClassifier.n_features_">
<span class="sig-name descname"><span class="pre">n_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.PivotForestClassifier.n_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The number of features when <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> is performed.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.0: </span>Attribute <cite>n_features_</cite> was deprecated in version 1.0 and will be
removed in 1.2. Use <cite>n_features_in_</cite> instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.PivotForestClassifier.n_features_in_">
<span class="sig-name descname"><span class="pre">n_features_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.PivotForestClassifier.n_features_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Number of features seen during <span class="xref std std-term">fit</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.PivotForestClassifier.feature_names_in_">
<span class="sig-name descname"><span class="pre">feature_names_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.PivotForestClassifier.feature_names_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Names of features seen during <span class="xref std std-term">fit</span>. Defined only when <cite>X</cite>
has feature names that are all strings.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (<cite>n_features_in_</cite>,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.PivotForestClassifier.estimators_">
<span class="sig-name descname"><span class="pre">estimators_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.PivotForestClassifier.estimators_" title="Permalink to this definition">#</a></dt>
<dd><p>The collection of fitted base estimators.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of estimators</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.PivotForestClassifier.estimators_samples_">
<span class="sig-name descname"><span class="pre">estimators_samples_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.PivotForestClassifier.estimators_samples_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn samples (i.e., the in-bag samples) for each base
estimator. Each subset is defined by an array of the indices selected.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.PivotForestClassifier.estimators_features_">
<span class="sig-name descname"><span class="pre">estimators_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.PivotForestClassifier.estimators_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn features for each base estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.PivotForestClassifier.classes_">
<span class="sig-name descname"><span class="pre">classes_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.PivotForestClassifier.classes_" title="Permalink to this definition">#</a></dt>
<dd><p>The classes labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_classes,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.PivotForestClassifier.n_classes_">
<span class="sig-name descname"><span class="pre">n_classes_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.PivotForestClassifier.n_classes_" title="Permalink to this definition">#</a></dt>
<dd><p>The number of classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int or list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.PivotForestClassifier.oob_score_">
<span class="sig-name descname"><span class="pre">oob_score_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.PivotForestClassifier.oob_score_" title="Permalink to this definition">#</a></dt>
<dd><p>Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.PivotForestClassifier.oob_decision_function_">
<span class="sig-name descname"><span class="pre">oob_decision_function_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.PivotForestClassifier.oob_decision_function_" title="Permalink to this definition">#</a></dt>
<dd><p>Decision function computed with out-of-bag estimate on the training
set. If n_estimators is small it might be possible that a data point
was never left out during the bootstrap. In this case,
<cite>oob_decision_function_</cite> might contain NaN. This attribute exists
only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_classes)</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaggingRegressor</span></code></dt><dd><p>A Bagging regressor.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id37" role="note">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Pasting small votes for classification in large
databases and on-line”, Machine Learning, 36(1), 85-103, 1999.</p>
</aside>
<aside class="footnote brackets" id="id38" role="note">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140,
1996.</p>
</aside>
<aside class="footnote brackets" id="id39" role="note">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>T. Ho, “The random subspace method for constructing decision
forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844,
1998.</p>
</aside>
<aside class="footnote brackets" id="id40" role="note">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine
Learning and Knowledge Discovery in Databases, 346-361, 2012.</p>
</aside>
</aside>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">SVC</span><span class="p">(),</span>
<span class="gp">... </span>                        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="go">array([1])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.ProximityForestClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">ProximityForestClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_pivot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pivot_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'label'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'weighted'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_factories</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'entropy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1695-L1758"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.ProximityForestClassifier" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier" title="wildboar.ensemble._ensemble.BaseForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseForestClassifier</span></code></a></p>
<p>A forest of proximity trees</p>
<p class="rubric">References</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">RockestClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_kernels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'entropy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1450-L1514"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestClassifier" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier" title="wildboar.ensemble._ensemble.BaseForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseForestClassifier</span></code></a></p>
<p>A Bagging classifier.</p>
<p>A Bagging classifier is an ensemble meta-estimator that fits base
classifiers each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.</p>
<p>This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting <a href="#id77"><span class="problematic" id="id41">[1]_</span></a>. If samples are drawn with
replacement, then the method is known as Bagging <a href="#id78"><span class="problematic" id="id42">[2]_</span></a>. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces <a href="#id79"><span class="problematic" id="id43">[3]_</span></a>. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches <a href="#id80"><span class="problematic" id="id44">[4]_</span></a>.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.15.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_estimator</strong> (<em>object</em><em>, </em><em>default=None</em>) – The base estimator to fit on random subsets of the dataset.
If None, then the base estimator is a
<code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code>.</p></li>
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>default=10</em>) – The number of base estimators in the ensemble.</p></li>
<li><p><strong>max_samples</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of samples to draw from X to train each base estimator (with
replacement by default, see <cite>bootstrap</cite> for more details).</p>
<ul>
<li><p>If int, then draw <cite>max_samples</cite> samples.</p></li>
<li><p>If float, then draw <cite>max_samples * X.shape[0]</cite> samples.</p></li>
</ul>
</p></li>
<li><p><strong>max_features</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of features to draw from X to train each base estimator (
without replacement by default, see <cite>bootstrap_features</cite> for more
details).</p>
<ul>
<li><p>If int, then draw <cite>max_features</cite> features.</p></li>
<li><p>If float, then draw <cite>max(1, int(max_features * n_features_in_))</cite> features.</p></li>
</ul>
</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Whether samples are drawn with replacement. If False, sampling
without replacement is performed.</p></li>
<li><p><strong>bootstrap_features</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether features are drawn with replacement.</p></li>
<li><p><strong>oob_score</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to use out-of-bag samples to estimate
the generalization error. Only available if bootstrap=True.</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>default=False</em>) – <p>When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble. See <span class="xref std std-term">the Glossary</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.17: </span><em>warm_start</em> constructor parameter.</p>
</div>
</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of jobs to run in parallel for both <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> and
<code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code>. <code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a
<code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all
processors. See <span class="xref std std-term">Glossary</span> for more details.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the random resampling of the original dataset
(sample wise and feature wise).
If the base estimator accepts a <cite>random_state</cite> attribute, a different
seed is generated for each instance in the ensemble.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – Controls the verbosity when fitting and predicting.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestClassifier.base_estimator_">
<span class="sig-name descname"><span class="pre">base_estimator_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestClassifier.base_estimator_" title="Permalink to this definition">#</a></dt>
<dd><p>The base estimator from which the ensemble is grown.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>estimator</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestClassifier.n_features_">
<span class="sig-name descname"><span class="pre">n_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestClassifier.n_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The number of features when <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> is performed.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.0: </span>Attribute <cite>n_features_</cite> was deprecated in version 1.0 and will be
removed in 1.2. Use <cite>n_features_in_</cite> instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestClassifier.n_features_in_">
<span class="sig-name descname"><span class="pre">n_features_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestClassifier.n_features_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Number of features seen during <span class="xref std std-term">fit</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestClassifier.feature_names_in_">
<span class="sig-name descname"><span class="pre">feature_names_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestClassifier.feature_names_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Names of features seen during <span class="xref std std-term">fit</span>. Defined only when <cite>X</cite>
has feature names that are all strings.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (<cite>n_features_in_</cite>,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestClassifier.estimators_">
<span class="sig-name descname"><span class="pre">estimators_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestClassifier.estimators_" title="Permalink to this definition">#</a></dt>
<dd><p>The collection of fitted base estimators.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of estimators</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestClassifier.estimators_samples_">
<span class="sig-name descname"><span class="pre">estimators_samples_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestClassifier.estimators_samples_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn samples (i.e., the in-bag samples) for each base
estimator. Each subset is defined by an array of the indices selected.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestClassifier.estimators_features_">
<span class="sig-name descname"><span class="pre">estimators_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestClassifier.estimators_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn features for each base estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestClassifier.classes_">
<span class="sig-name descname"><span class="pre">classes_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestClassifier.classes_" title="Permalink to this definition">#</a></dt>
<dd><p>The classes labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_classes,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestClassifier.n_classes_">
<span class="sig-name descname"><span class="pre">n_classes_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestClassifier.n_classes_" title="Permalink to this definition">#</a></dt>
<dd><p>The number of classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int or list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestClassifier.oob_score_">
<span class="sig-name descname"><span class="pre">oob_score_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestClassifier.oob_score_" title="Permalink to this definition">#</a></dt>
<dd><p>Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestClassifier.oob_decision_function_">
<span class="sig-name descname"><span class="pre">oob_decision_function_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestClassifier.oob_decision_function_" title="Permalink to this definition">#</a></dt>
<dd><p>Decision function computed with out-of-bag estimate on the training
set. If n_estimators is small it might be possible that a data point
was never left out during the bootstrap. In this case,
<cite>oob_decision_function_</cite> might contain NaN. This attribute exists
only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_samples, n_classes)</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaggingRegressor</span></code></dt><dd><p>A Bagging regressor.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id45" role="note">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Pasting small votes for classification in large
databases and on-line”, Machine Learning, 36(1), 85-103, 1999.</p>
</aside>
<aside class="footnote brackets" id="id46" role="note">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140,
1996.</p>
</aside>
<aside class="footnote brackets" id="id47" role="note">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>T. Ho, “The random subspace method for constructing decision
forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844,
1998.</p>
</aside>
<aside class="footnote brackets" id="id48" role="note">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine
Learning and Knowledge Discovery in Databases, 346-361, 2012.</p>
</aside>
</aside>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">SVC</span><span class="p">(),</span>
<span class="gp">... </span>                        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="go">array([1])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">RockestRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_kernels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1385-L1447"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestRegressor" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor" title="wildboar.ensemble._ensemble.BaseForestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseForestRegressor</span></code></a></p>
<p>A Bagging regressor.</p>
<p>A Bagging regressor is an ensemble meta-estimator that fits base
regressors each on random subsets of the original dataset and then
aggregate their individual predictions (either by voting or by averaging)
to form a final prediction. Such a meta-estimator can typically be used as
a way to reduce the variance of a black-box estimator (e.g., a decision
tree), by introducing randomization into its construction procedure and
then making an ensemble out of it.</p>
<p>This algorithm encompasses several works from the literature. When random
subsets of the dataset are drawn as random subsets of the samples, then
this algorithm is known as Pasting <a href="#id81"><span class="problematic" id="id49">[1]_</span></a>. If samples are drawn with
replacement, then the method is known as Bagging <a href="#id82"><span class="problematic" id="id50">[2]_</span></a>. When random subsets
of the dataset are drawn as random subsets of the features, then the method
is known as Random Subspaces <a href="#id83"><span class="problematic" id="id51">[3]_</span></a>. Finally, when base estimators are built
on subsets of both samples and features, then the method is known as
Random Patches <a href="#id84"><span class="problematic" id="id52">[4]_</span></a>.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.15.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_estimator</strong> (<em>object</em><em>, </em><em>default=None</em>) – The base estimator to fit on random subsets of the dataset.
If None, then the base estimator is a
<code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code>.</p></li>
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>default=10</em>) – The number of base estimators in the ensemble.</p></li>
<li><p><strong>max_samples</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of samples to draw from X to train each base estimator (with
replacement by default, see <cite>bootstrap</cite> for more details).</p>
<ul>
<li><p>If int, then draw <cite>max_samples</cite> samples.</p></li>
<li><p>If float, then draw <cite>max_samples * X.shape[0]</cite> samples.</p></li>
</ul>
</p></li>
<li><p><strong>max_features</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>default=1.0</em>) – <p>The number of features to draw from X to train each base estimator (
without replacement by default, see <cite>bootstrap_features</cite> for more
details).</p>
<ul>
<li><p>If int, then draw <cite>max_features</cite> features.</p></li>
<li><p>If float, then draw <cite>max(1, int(max_features * n_features_in_))</cite> features.</p></li>
</ul>
</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>default=True</em>) – Whether samples are drawn with replacement. If False, sampling
without replacement is performed.</p></li>
<li><p><strong>bootstrap_features</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether features are drawn with replacement.</p></li>
<li><p><strong>oob_score</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether to use out-of-bag samples to estimate
the generalization error. Only available if bootstrap=True.</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>default=False</em>) – When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble. See <span class="xref std std-term">the Glossary</span>.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of jobs to run in parallel for both <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> and
<code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code>. <code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a
<code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all
processors. See <span class="xref std std-term">Glossary</span> for more details.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Controls the random resampling of the original dataset
(sample wise and feature wise).
If the base estimator accepts a <cite>random_state</cite> attribute, a different
seed is generated for each instance in the ensemble.
Pass an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – Controls the verbosity when fitting and predicting.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestRegressor.base_estimator_">
<span class="sig-name descname"><span class="pre">base_estimator_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestRegressor.base_estimator_" title="Permalink to this definition">#</a></dt>
<dd><p>The base estimator from which the ensemble is grown.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>estimator</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestRegressor.n_features_">
<span class="sig-name descname"><span class="pre">n_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestRegressor.n_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The number of features when <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> is performed.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.0: </span>Attribute <cite>n_features_</cite> was deprecated in version 1.0 and will be
removed in 1.2. Use <cite>n_features_in_</cite> instead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestRegressor.n_features_in_">
<span class="sig-name descname"><span class="pre">n_features_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestRegressor.n_features_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Number of features seen during <span class="xref std std-term">fit</span>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.24.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestRegressor.feature_names_in_">
<span class="sig-name descname"><span class="pre">feature_names_in_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestRegressor.feature_names_in_" title="Permalink to this definition">#</a></dt>
<dd><p>Names of features seen during <span class="xref std std-term">fit</span>. Defined only when <cite>X</cite>
has feature names that are all strings.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (<cite>n_features_in_</cite>,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestRegressor.estimators_">
<span class="sig-name descname"><span class="pre">estimators_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestRegressor.estimators_" title="Permalink to this definition">#</a></dt>
<dd><p>The collection of fitted sub-estimators.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of estimators</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestRegressor.estimators_samples_">
<span class="sig-name descname"><span class="pre">estimators_samples_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestRegressor.estimators_samples_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn samples (i.e., the in-bag samples) for each base
estimator. Each subset is defined by an array of the indices selected.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestRegressor.estimators_features_">
<span class="sig-name descname"><span class="pre">estimators_features_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestRegressor.estimators_features_" title="Permalink to this definition">#</a></dt>
<dd><p>The subset of drawn features for each base estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of arrays</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestRegressor.oob_score_">
<span class="sig-name descname"><span class="pre">oob_score_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestRegressor.oob_score_" title="Permalink to this definition">#</a></dt>
<dd><p>Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.RockestRegressor.oob_prediction_">
<span class="sig-name descname"><span class="pre">oob_prediction_</span></span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.RockestRegressor.oob_prediction_" title="Permalink to this definition">#</a></dt>
<dd><p>Prediction computed with out-of-bag estimate on the training
set. If n_estimators is small it might be possible that a data point
was never left out during the bootstrap. In this case,
<cite>oob_prediction_</cite> might contain NaN. This attribute exists only
when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaggingClassifier</span></code></dt><dd><p>A Bagging classifier.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id53" role="note">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Pasting small votes for classification in large
databases and on-line”, Machine Learning, 36(1), 85-103, 1999.</p>
</aside>
<aside class="footnote brackets" id="id54" role="note">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140,
1996.</p>
</aside>
<aside class="footnote brackets" id="id55" role="note">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>T. Ho, “The random subspace method for constructing decision
forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844,
1998.</p>
</aside>
<aside class="footnote brackets" id="id56" role="note">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine
Learning and Knowledge Discovery in Databases, 346-361, 2012.</p>
</aside>
</aside>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_targets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span> <span class="o">=</span> <span class="n">BaggingRegressor</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">SVR</span><span class="p">(),</span>
<span class="gp">... </span>                        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="go">array([-2.8720...])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.ShapeletForestClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">ShapeletForestClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_shapelets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'entropy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L280-L432"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.ShapeletForestClassifier" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseShapeletForestClassifier" title="wildboar.ensemble._ensemble.BaseShapeletForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseShapeletForestClassifier</span></code></a></p>
<p>An ensemble of random shapelet tree classifiers.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.ensemble</span> <span class="kn">import</span> <span class="n">ShapeletForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.datasets</span> <span class="kn">import</span> <span class="n">load_synthetic_control</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_synthetic_control</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">ShapeletForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;scaled_euclidean&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Shapelet forest classifier.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of estimators</p></li>
<li><p><strong>n_shapelets</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of shapelets to sample at each node</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use bootstrap sampling to fit the base estimators</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of processor cores used for fitting the ensemble</p></li>
<li><p><strong>min_shapelet_size</strong> (<em>float</em><em>, </em><em>optional</em>) – The minimum shapelet size to sample</p></li>
<li><p><strong>max_shapelet_size</strong> (<em>float</em><em>, </em><em>optional</em>) – The maximum shapelet size to sample</p></li>
<li><p><strong>min_samples_split</strong> (<em>int</em><em>, </em><em>optional</em>) – The minimum samples required to split the decision trees</p></li>
<li><p><strong>min_samples_leaf</strong> (<em>int</em><em>, </em><em>optional</em>) – The minimum number of samples in a leaf</p></li>
<li><p><strong>criterion</strong> (<em>{&quot;entropy&quot;</em><em>, </em><em>&quot;gini&quot;}</em><em>, </em><em>optional</em>) – The criterion used to evaluate the utility of a split</p></li>
<li><p><strong>min_impurity_decrease</strong> (<em>float</em><em>, </em><em>optional</em>) – A split will be introduced only if the impurity decrease is larger than or
equal to this value</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble.</p></li>
<li><p><strong>metric</strong> (<em>{'euclidean'</em><em>, </em><em>'scaled_euclidean'</em><em>, </em><em>'scaled_dtw'}</em><em>, </em><em>optional</em>) – Set the metric used to compute the distance between shapelet and time series</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – Parameters passed to the metric construction</p></li>
<li><p><strong>oob_score</strong> (<em>bool</em><em>, </em><em>optional</em>) – Compute out-of-bag estimates of the ensembles performance.</p></li>
<li><p><strong>class_weight</strong> (<em>dict</em><em> or </em><em>&quot;balanced&quot;</em><em>, </em><em>optional</em>) – <p>Weights associated with the labels</p>
<ul>
<li><p>if dict, weights on the form {label: weight}</p></li>
<li><p>if “balanced” each class weight inversely proportional to the class
frequency</p></li>
<li><p>if None, each class has equal weight</p></li>
</ul>
</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>RandomState</em><em>, </em><em>optional</em>) – Controls the random resampling of the original dataset and the construction
of the base estimators. Pass an int for reproducible output across multiple
function calls.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.ShapeletForestEmbedding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">ShapeletForestEmbedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_shapelets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L934-L1061"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseShapeletForestRegressor" title="wildboar.ensemble._ensemble.BaseShapeletForestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseShapeletForestRegressor</span></code></a></p>
<p>An ensemble of random shapelet trees</p>
<p>An unsupervised transformation of a time series dataset
to a high-dimensional sparse representation. A time series i
indexed by the leaf that it falls into. This leads to a binary
coding of a time series with as many ones as trees in the forest.</p>
<p>The dimensionality of the resulting representation is
<code class="docutils literal notranslate"><span class="pre">&lt;=</span> <span class="pre">n_estimators</span> <span class="pre">*</span> <span class="pre">2^max_depth</span></code></p>
<p>Construct a shapelet forest embedding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of estimators</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use bootstrap sampling to fit the base estimators</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of processor cores used for fitting the ensemble</p></li>
<li><p><strong>min_shapelet_size</strong> (<em>float</em><em>, </em><em>optional</em>) – The minimum shapelet size to sample</p></li>
<li><p><strong>max_shapelet_size</strong> (<em>float</em><em>, </em><em>optional</em>) – The maximum shapelet size to sample</p></li>
<li><p><strong>min_samples_split</strong> (<em>int</em><em>, </em><em>optional</em>) – The minimum samples required to split the decision trees</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble.</p></li>
<li><p><strong>metric</strong> (<em>{'euclidean'</em><em>, </em><em>'scaled_euclidean'</em><em>, </em><em>'scaled_dtw'}</em><em>, </em><em>optional</em>) – Set the metric used to compute the distance between shapelet and time series</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – Parameters passed to the metric construction</p></li>
<li><p><strong>sparse_output</strong> (<em>bool</em><em>, </em><em>optional</em>) – Return a sparse CSR-matrix.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>RandomState</em><em>, </em><em>optional</em>) – Controls the random resampling of the original dataset and the construction
of the base estimators. Pass an int for reproducible output across multiple
function calls.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.ShapeletForestEmbedding.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_input</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1045-L1047"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding.fit" title="Permalink to this definition">#</a></dt>
<dd><p>Build a Bagging ensemble of estimators from the training set (X, y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples. Sparse matrices are accepted only if
they are supported by the base estimator.</p></li>
<li><p><strong>y</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The target values (class labels in classification, real numbers in
regression).</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights. If None, then samples are equally weighted.
Note that this is supported only if the base estimator supports
sample weighting.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>self</strong> – Fitted estimator.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.ShapeletForestEmbedding.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_input</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1049-L1057"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding.fit_transform" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.ShapeletForestEmbedding.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L1059-L1061"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding.transform" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="wildboar.ensemble._ensemble.ShapeletForestRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wildboar.ensemble._ensemble.</span></span><span class="sig-name descname"><span class="pre">ShapeletForestRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_shapelets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_shapelet_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/isaksamsten/wildboar/blob/1.1.X/src/wildboar/ensemble/_ensemble.py#L699-L830"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wildboar.ensemble._ensemble.ShapeletForestRegressor" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#wildboar.ensemble._ensemble.BaseShapeletForestRegressor" title="wildboar.ensemble._ensemble.BaseShapeletForestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseShapeletForestRegressor</span></code></a></p>
<p>An ensemble of random shapelet regression trees.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.ensemble</span> <span class="kn">import</span> <span class="n">ShapeletForestRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">wildboar.datasets</span> <span class="kn">import</span> <span class="n">load_synthetic_control</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_synthetic_control</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">ShapeletForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;scaled_euclidean&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Shapelet forest regressor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of estimators</p></li>
<li><p><strong>n_shapelets</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of shapelets to sample at each node</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>optional</em>) – Use bootstrap sampling to fit the base estimators</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of processor cores used for fitting the ensemble</p></li>
<li><p><strong>min_shapelet_size</strong> (<em>float</em><em>, </em><em>optional</em>) – The minimum shapelet size to sample</p></li>
<li><p><strong>max_shapelet_size</strong> (<em>float</em><em>, </em><em>optional</em>) – The maximum shapelet size to sample</p></li>
<li><p><strong>min_samples_split</strong> (<em>int</em><em>, </em><em>optional</em>) – The minimum samples required to split the decision trees</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em><em>, </em><em>optional</em>) – When set to True, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit
a whole new ensemble.</p></li>
<li><p><strong>metric</strong> (<em>{'euclidean'</em><em>, </em><em>'scaled_euclidean'</em><em>, </em><em>'scaled_dtw'}</em><em>, </em><em>optional</em>) – Set the metric used to compute the distance between shapelet and time series</p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – Parameters passed to the metric construction</p></li>
<li><p><strong>oob_score</strong> (<em>bool</em><em>, </em><em>optional</em>) – Compute out-of-bag estimates of the ensembles performance.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>RandomState</em><em>, </em><em>optional</em>) – Controls the random resampling of the original dataset and the construction
of the base estimators. Pass an int for reproducible output across multiple
function calls.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2020, Isak Samsten
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wildboar.ensemble._ensemble</span></code></a><ul>
<li><a class="reference internal" href="#module-contents">Module Contents</a><ul>
<li><a class="reference internal" href="#classes">Classes</a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier</span></code></a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.base_estimator_"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.base_estimator_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.n_features_"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.n_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.n_features_in_"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.n_features_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.feature_names_in_"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.feature_names_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.estimators_"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.estimators_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.estimators_samples_"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.estimators_samples_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.estimators_features_"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.estimators_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.classes_"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.classes_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.n_classes_"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.n_classes_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.oob_score_"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.oob_score_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.oob_decision_function_"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.oob_decision_function_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.fit"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.fit()</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.predict"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.predict()</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.predict_log_proba"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.predict_log_proba()</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.predict_proba"><code class="docutils literal notranslate"><span class="pre">BaseForestClassifier.predict_proba()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor"><code class="docutils literal notranslate"><span class="pre">BaseForestRegressor</span></code></a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.base_estimator_"><code class="docutils literal notranslate"><span class="pre">BaseForestRegressor.base_estimator_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.n_features_"><code class="docutils literal notranslate"><span class="pre">BaseForestRegressor.n_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.n_features_in_"><code class="docutils literal notranslate"><span class="pre">BaseForestRegressor.n_features_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.feature_names_in_"><code class="docutils literal notranslate"><span class="pre">BaseForestRegressor.feature_names_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.estimators_"><code class="docutils literal notranslate"><span class="pre">BaseForestRegressor.estimators_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.estimators_samples_"><code class="docutils literal notranslate"><span class="pre">BaseForestRegressor.estimators_samples_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.estimators_features_"><code class="docutils literal notranslate"><span class="pre">BaseForestRegressor.estimators_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.oob_score_"><code class="docutils literal notranslate"><span class="pre">BaseForestRegressor.oob_score_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.oob_prediction_"><code class="docutils literal notranslate"><span class="pre">BaseForestRegressor.oob_prediction_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.fit"><code class="docutils literal notranslate"><span class="pre">BaseForestRegressor.fit()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseShapeletForestClassifier"><code class="docutils literal notranslate"><span class="pre">BaseShapeletForestClassifier</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseShapeletForestRegressor"><code class="docutils literal notranslate"><span class="pre">BaseShapeletForestRegressor</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ExtraShapeletTreesClassifier"><code class="docutils literal notranslate"><span class="pre">ExtraShapeletTreesClassifier</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ExtraShapeletTreesRegressor"><code class="docutils literal notranslate"><span class="pre">ExtraShapeletTreesRegressor</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ForestMixin"><code class="docutils literal notranslate"><span class="pre">ForestMixin</span></code></a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ForestMixin.apply"><code class="docutils literal notranslate"><span class="pre">ForestMixin.apply()</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ForestMixin.decision_path"><code class="docutils literal notranslate"><span class="pre">ForestMixin.decision_path()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier"><code class="docutils literal notranslate"><span class="pre">IntervalForestClassifier</span></code></a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.base_estimator_"><code class="docutils literal notranslate"><span class="pre">IntervalForestClassifier.base_estimator_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.n_features_"><code class="docutils literal notranslate"><span class="pre">IntervalForestClassifier.n_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.n_features_in_"><code class="docutils literal notranslate"><span class="pre">IntervalForestClassifier.n_features_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.feature_names_in_"><code class="docutils literal notranslate"><span class="pre">IntervalForestClassifier.feature_names_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.estimators_"><code class="docutils literal notranslate"><span class="pre">IntervalForestClassifier.estimators_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.estimators_samples_"><code class="docutils literal notranslate"><span class="pre">IntervalForestClassifier.estimators_samples_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.estimators_features_"><code class="docutils literal notranslate"><span class="pre">IntervalForestClassifier.estimators_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.classes_"><code class="docutils literal notranslate"><span class="pre">IntervalForestClassifier.classes_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.n_classes_"><code class="docutils literal notranslate"><span class="pre">IntervalForestClassifier.n_classes_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.oob_score_"><code class="docutils literal notranslate"><span class="pre">IntervalForestClassifier.oob_score_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.oob_decision_function_"><code class="docutils literal notranslate"><span class="pre">IntervalForestClassifier.oob_decision_function_</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor"><code class="docutils literal notranslate"><span class="pre">IntervalForestRegressor</span></code></a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.base_estimator_"><code class="docutils literal notranslate"><span class="pre">IntervalForestRegressor.base_estimator_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.n_features_"><code class="docutils literal notranslate"><span class="pre">IntervalForestRegressor.n_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.n_features_in_"><code class="docutils literal notranslate"><span class="pre">IntervalForestRegressor.n_features_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.feature_names_in_"><code class="docutils literal notranslate"><span class="pre">IntervalForestRegressor.feature_names_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.estimators_"><code class="docutils literal notranslate"><span class="pre">IntervalForestRegressor.estimators_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.estimators_samples_"><code class="docutils literal notranslate"><span class="pre">IntervalForestRegressor.estimators_samples_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.estimators_features_"><code class="docutils literal notranslate"><span class="pre">IntervalForestRegressor.estimators_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.oob_score_"><code class="docutils literal notranslate"><span class="pre">IntervalForestRegressor.oob_score_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.oob_prediction_"><code class="docutils literal notranslate"><span class="pre">IntervalForestRegressor.oob_prediction_</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest"><code class="docutils literal notranslate"><span class="pre">IsolationShapeletForest</span></code></a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.offset_"><code class="docutils literal notranslate"><span class="pre">IsolationShapeletForest.offset_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.decision_function"><code class="docutils literal notranslate"><span class="pre">IsolationShapeletForest.decision_function()</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.fit"><code class="docutils literal notranslate"><span class="pre">IsolationShapeletForest.fit()</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.predict"><code class="docutils literal notranslate"><span class="pre">IsolationShapeletForest.predict()</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.score_samples"><code class="docutils literal notranslate"><span class="pre">IsolationShapeletForest.score_samples()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier"><code class="docutils literal notranslate"><span class="pre">PivotForestClassifier</span></code></a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.base_estimator_"><code class="docutils literal notranslate"><span class="pre">PivotForestClassifier.base_estimator_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.n_features_"><code class="docutils literal notranslate"><span class="pre">PivotForestClassifier.n_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.n_features_in_"><code class="docutils literal notranslate"><span class="pre">PivotForestClassifier.n_features_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.feature_names_in_"><code class="docutils literal notranslate"><span class="pre">PivotForestClassifier.feature_names_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.estimators_"><code class="docutils literal notranslate"><span class="pre">PivotForestClassifier.estimators_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.estimators_samples_"><code class="docutils literal notranslate"><span class="pre">PivotForestClassifier.estimators_samples_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.estimators_features_"><code class="docutils literal notranslate"><span class="pre">PivotForestClassifier.estimators_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.classes_"><code class="docutils literal notranslate"><span class="pre">PivotForestClassifier.classes_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.n_classes_"><code class="docutils literal notranslate"><span class="pre">PivotForestClassifier.n_classes_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.oob_score_"><code class="docutils literal notranslate"><span class="pre">PivotForestClassifier.oob_score_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.oob_decision_function_"><code class="docutils literal notranslate"><span class="pre">PivotForestClassifier.oob_decision_function_</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ProximityForestClassifier"><code class="docutils literal notranslate"><span class="pre">ProximityForestClassifier</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier"><code class="docutils literal notranslate"><span class="pre">RockestClassifier</span></code></a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.base_estimator_"><code class="docutils literal notranslate"><span class="pre">RockestClassifier.base_estimator_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.n_features_"><code class="docutils literal notranslate"><span class="pre">RockestClassifier.n_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.n_features_in_"><code class="docutils literal notranslate"><span class="pre">RockestClassifier.n_features_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.feature_names_in_"><code class="docutils literal notranslate"><span class="pre">RockestClassifier.feature_names_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.estimators_"><code class="docutils literal notranslate"><span class="pre">RockestClassifier.estimators_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.estimators_samples_"><code class="docutils literal notranslate"><span class="pre">RockestClassifier.estimators_samples_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.estimators_features_"><code class="docutils literal notranslate"><span class="pre">RockestClassifier.estimators_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.classes_"><code class="docutils literal notranslate"><span class="pre">RockestClassifier.classes_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.n_classes_"><code class="docutils literal notranslate"><span class="pre">RockestClassifier.n_classes_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.oob_score_"><code class="docutils literal notranslate"><span class="pre">RockestClassifier.oob_score_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.oob_decision_function_"><code class="docutils literal notranslate"><span class="pre">RockestClassifier.oob_decision_function_</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor"><code class="docutils literal notranslate"><span class="pre">RockestRegressor</span></code></a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.base_estimator_"><code class="docutils literal notranslate"><span class="pre">RockestRegressor.base_estimator_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.n_features_"><code class="docutils literal notranslate"><span class="pre">RockestRegressor.n_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.n_features_in_"><code class="docutils literal notranslate"><span class="pre">RockestRegressor.n_features_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.feature_names_in_"><code class="docutils literal notranslate"><span class="pre">RockestRegressor.feature_names_in_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.estimators_"><code class="docutils literal notranslate"><span class="pre">RockestRegressor.estimators_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.estimators_samples_"><code class="docutils literal notranslate"><span class="pre">RockestRegressor.estimators_samples_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.estimators_features_"><code class="docutils literal notranslate"><span class="pre">RockestRegressor.estimators_features_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.oob_score_"><code class="docutils literal notranslate"><span class="pre">RockestRegressor.oob_score_</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.oob_prediction_"><code class="docutils literal notranslate"><span class="pre">RockestRegressor.oob_prediction_</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestClassifier"><code class="docutils literal notranslate"><span class="pre">ShapeletForestClassifier</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding"><code class="docutils literal notranslate"><span class="pre">ShapeletForestEmbedding</span></code></a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding.fit"><code class="docutils literal notranslate"><span class="pre">ShapeletForestEmbedding.fit()</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding.fit_transform"><code class="docutils literal notranslate"><span class="pre">ShapeletForestEmbedding.fit_transform()</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding.transform"><code class="docutils literal notranslate"><span class="pre">ShapeletForestEmbedding.transform()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestRegressor"><code class="docutils literal notranslate"><span class="pre">ShapeletForestRegressor</span></code></a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier">BaseForestClassifier</a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.base_estimator_">base_estimator_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.n_features_">n_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.n_features_in_">n_features_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.feature_names_in_">feature_names_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.estimators_">estimators_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.estimators_samples_">estimators_samples_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.estimators_features_">estimators_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.classes_">classes_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.n_classes_">n_classes_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.oob_score_">oob_score_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.oob_decision_function_">oob_decision_function_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.fit">fit</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.predict">predict</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.predict_log_proba">predict_log_proba</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestClassifier.predict_proba">predict_proba</a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor">BaseForestRegressor</a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.base_estimator_">base_estimator_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.n_features_">n_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.n_features_in_">n_features_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.feature_names_in_">feature_names_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.estimators_">estimators_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.estimators_samples_">estimators_samples_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.estimators_features_">estimators_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.oob_score_">oob_score_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.oob_prediction_">oob_prediction_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseForestRegressor.fit">fit</a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseShapeletForestClassifier">BaseShapeletForestClassifier</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.BaseShapeletForestRegressor">BaseShapeletForestRegressor</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ExtraShapeletTreesClassifier">ExtraShapeletTreesClassifier</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ExtraShapeletTreesRegressor">ExtraShapeletTreesRegressor</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ForestMixin">ForestMixin</a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ForestMixin.apply">apply</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ForestMixin.decision_path">decision_path</a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier">IntervalForestClassifier</a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.base_estimator_">base_estimator_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.n_features_">n_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.n_features_in_">n_features_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.feature_names_in_">feature_names_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.estimators_">estimators_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.estimators_samples_">estimators_samples_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.estimators_features_">estimators_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.classes_">classes_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.n_classes_">n_classes_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.oob_score_">oob_score_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestClassifier.oob_decision_function_">oob_decision_function_</a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor">IntervalForestRegressor</a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.base_estimator_">base_estimator_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.n_features_">n_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.n_features_in_">n_features_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.feature_names_in_">feature_names_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.estimators_">estimators_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.estimators_samples_">estimators_samples_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.estimators_features_">estimators_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.oob_score_">oob_score_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IntervalForestRegressor.oob_prediction_">oob_prediction_</a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest">IsolationShapeletForest</a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.offset_">offset_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.decision_function">decision_function</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.fit">fit</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.predict">predict</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.IsolationShapeletForest.score_samples">score_samples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier">PivotForestClassifier</a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.base_estimator_">base_estimator_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.n_features_">n_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.n_features_in_">n_features_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.feature_names_in_">feature_names_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.estimators_">estimators_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.estimators_samples_">estimators_samples_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.estimators_features_">estimators_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.classes_">classes_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.n_classes_">n_classes_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.oob_score_">oob_score_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.PivotForestClassifier.oob_decision_function_">oob_decision_function_</a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ProximityForestClassifier">ProximityForestClassifier</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier">RockestClassifier</a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.base_estimator_">base_estimator_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.n_features_">n_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.n_features_in_">n_features_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.feature_names_in_">feature_names_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.estimators_">estimators_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.estimators_samples_">estimators_samples_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.estimators_features_">estimators_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.classes_">classes_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.n_classes_">n_classes_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.oob_score_">oob_score_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestClassifier.oob_decision_function_">oob_decision_function_</a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor">RockestRegressor</a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.base_estimator_">base_estimator_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.n_features_">n_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.n_features_in_">n_features_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.feature_names_in_">feature_names_in_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.estimators_">estimators_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.estimators_samples_">estimators_samples_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.estimators_features_">estimators_features_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.oob_score_">oob_score_</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.RockestRegressor.oob_prediction_">oob_prediction_</a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestClassifier">ShapeletForestClassifier</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding">ShapeletForestEmbedding</a><ul>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding.fit">fit</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding.fit_transform">fit_transform</a></li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestEmbedding.transform">transform</a></li>
</ul>
</li>
<li><a class="reference internal" href="#wildboar.ensemble._ensemble.ShapeletForestRegressor">ShapeletForestRegressor</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/scripts/furo.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/design-tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>