:py:mod:`wildboar.model_selection.outlier`
==========================================

.. py:module:: wildboar.model_selection.outlier


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   wildboar.model_selection.outlier.RepeatedOutlierSplit



Functions
~~~~~~~~~

.. autoapisummary::

   wildboar.model_selection.outlier.threshold_score
   wildboar.model_selection.outlier.train_test_split



.. py:class:: RepeatedOutlierSplit(n_splits=None, *, test_size=0.2, n_outlier=0.05, shuffle=True, random_state=None)

   Repeated random outlier cross-validator.

   Yields indicies that split the dataset into training and test sets.

   .. note::

      Contrary to other cross-validation strategies, the random outlier
      cross-validator does not ensure that all folds will be different.
      Instead, the inlier samples are shuffled and new outlier samples
      are inserted in the training and test sets repeatedly.

      :param n_splits: The maximum number of splits.

                       - if None, the number of splits is determined by the number of
                         outliers as, `total_n_outliers/(n_inliers * n_outliers)`

                       - if int, the number of splits is an upper-bound
      :type n_splits: int, optional
      :param test_size: The size of the test set.
      :type test_size: float, optional
      :param n_outlier: The fraction of outliers in the training and test sets.
      :type n_outlier: float, optional
      :param shuffle: Shuffle the training indicies in each iteration.
      :type shuffle: bool, optional
      :param random_state: The psudo-random number generator
      :type random_state: int or RandomState, optional

   .. py:method:: __repr__()

      Return repr(self).


   .. py:method:: get_n_splits(X, y, groups=None)

      Returns the number of splitting iterations in the cross-validator
      :param X: The samples
      :type X: object
      :param y: The labels
      :type y: object
      :param groups: Always ignored, exists for compatibility.
      :type groups: object

      :returns: **n_splits** -- Returns the number of splitting iterations in the cross-validator.
      :rtype: int


   .. py:method:: split(x, y, groups=None)

      Return training and test indicies.

      :param x: Always ignored, exists for compatibility.
      :type x: object
      :param y: The labels
      :type y: object
      :param groups: Always ignored, exists for compatibility.
      :type groups: object, optional

      :Yields: **train_idx, test_idx** (*ndarray*) -- The training and test indicies



.. py:function:: threshold_score(y_true, score, score_f)

   Compute the performance of using the i:th score.

   The scores are typically computed using an outlier detection algorithm

   :param y_true: The true labels
   :type y_true: array-like
   :param score: The scores
   :type score: array-like
   :param score_f: Function for estimating the performance of the i:th scoring
   :type score_f: callable

   :returns: **score** -- performance for each score as threshold
   :rtype: ndarray

   .. seealso::

      :obj:`wildboar.ensemble.IsolationShapeletForest`
          an isolation forest for time series

   .. rubric:: Examples

   Setting the offset that maximizes balanced accuracy of a shapelet isolation forest

   >>> from wildboar.ensemble import IsolationShapeletForest
   >>> from wildboar.datasets import load_two_lead_ecg
   >>> from sklearn.metrics import balanced_accuracy_score
   >>> x, y = load_two_lead_ecg()
   >>> x_train, x_test, y_train, y_test = train_test_split(
   ...     x, y, 1, test_size=0.2, anomalies_train_size=0.05
   ... )
   >>> f = IsolationShapeletForest()
   >>> f.fit(x_train)
   >>> scores = f.score_samples(x_train)
   >>> perf = threshold_score(y_train, scores, balanced_accuracy_score)
   >>> f.offset_ = score[np.argmax(perf)]


.. py:function:: train_test_split(x, y, normal_class, test_size=0.2, anomalies_train_size=0.05, random_state=None)

   Training and testing split from classification dataset.

   :param x: Input data samples
   :type x: array-like of shape (n_samples, n_timestep) or (n_samples, n_dim, n_timestep)
   :param y: Input class label
   :type y: array-like of shape (n_samples,)
   :param normal_class: Class label that should be considered as the normal class
   :type normal_class: int
   :param test_size: Size of the test set
   :type test_size: float
   :param anomalies_train_size: Contamination of anomalies in the training dataset
   :type anomalies_train_size: float
   :param random_state: Psudo random state used for stable results.
   :type random_state: int or RandomState

   :returns: * **x_train** (*array-like*) -- Training samples
             * **x_test** (*array-like*) -- Test samples
             * **y_train** (*array-like*) -- Training labels (either 1 or -1, where 1 denotes normal and -1 anomalous)
             * **y_test** (*array-like*) -- Test labels (either 1 or -1, where 1 denotes normal and -1 anomalous)

   .. rubric:: Examples

   >>> from wildboar.datasets import load_two_lead_ecg
   >>> x, y = load_two_lead_ecg()
   >>> x_train, x_test, y_train, y_test = train_test_split(
   ...     x, y, 1, test_size=0.2, anomalies_train_size=0.05
   ... )


