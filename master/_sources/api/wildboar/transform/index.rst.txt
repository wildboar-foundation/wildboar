
****************************
:py:mod:`wildboar.transform`
****************************

.. py:module:: wildboar.transform

.. autoapi-nested-parse::

   
   Transform raw time series to tabular representations.
















   ..
       !! processed by numpydoc !!



Classes
-------

.. autoapisummary::

   wildboar.transform.CastorTransform
   wildboar.transform.DerivativeTransform
   wildboar.transform.DiffTransform
   wildboar.transform.DilatedShapeletTransform
   wildboar.transform.FeatureTransform
   wildboar.transform.FftTransform
   wildboar.transform.HydraTransform
   wildboar.transform.IntervalTransform
   wildboar.transform.MatrixProfileTransform
   wildboar.transform.PAA
   wildboar.transform.PivotTransform
   wildboar.transform.ProximityTransform
   wildboar.transform.QuantTransform
   wildboar.transform.RandomShapeletTransform
   wildboar.transform.RocketTransform
   wildboar.transform.SAX
   wildboar.transform.ShapeletTransform



Functions
---------

.. autoapisummary::

   wildboar.transform.convolve
   wildboar.transform.piecewice_aggregate_approximation
   wildboar.transform.symbolic_aggregate_approximation




.. raw:: html

   <br />

.. py:class:: CastorTransform(n_groups=64, n_shapelets=8, *, metric='euclidean', metric_params=None, normalize_prob=0.8, shapelet_size=11, lower=0.05, upper=0.1, soft_min=True, soft_max=False, soft_threshold=True, ignore_y=False, random_state=None, n_jobs=None)



   
   Competing Dialated Shapelet Transform.


   :Parameters:

       **n_groups** : int, optional
           The number of groups of dilated shapelets.

       **n_shapelets** : int, optional
           The number of dilated shapelets per group.

       **metric** : str or callable, optional
           The distance metric
           
           See ``_METRICS.keys()`` for a list of supported metrics.

       **metric_params** : dict, optional
           Parameters to the metric.
           
           Read more about the parameters in the
           :ref:`User guide <list_of_metrics>`.

       **normalize_prob** : float, optional
           The probability of standardizing a shapelet with zero mean and unit
           standard deviation.

       **shapelet_size** : int, optional
           The length of the dilated shapelet.

       **lower** : float, optional
           The lower percentile to draw distance thresholds above.

       **upper** : float, optional
           The upper percentile to draw distance thresholds below.

       **soft_min** : bool, optional
           If `True`, use the sum of minimal distances. Otherwise, use the count
           of minimal distances.

       **soft_max** : bool, optional
           If `True`, use the sum of maximal distances. Otherwise, use the count
           of maximal distances.

       **soft_threshold** : bool, optional
           If `True`, count the time steps below the threshold for all shapelets.
           Otherwise, count the time steps below the threshold for the shapelet
           with the minimal distance.

       **ignore_y** : bool, optional
           Ignore `y` and use the same sample which a shapelet is sampled from to
           estimate the distance threshold.

       **random_state** : int or RandomState, optional
           Controls the random sampling of kernels.
           
           - If `int`, `random_state` is the seed used by the random number
             generator.
           - If :class:`numpy.random.RandomState` instance, `random_state` is
             the random number generator.
           - If `None`, the random number generator is the
             :class:`numpy.random.RandomState` instance used by
             :func:`numpy.random`.

       **n_jobs** : int, optional
           The number of parallel jobs.











   .. rubric:: Notes

   For better performance with multivariate datasets, set `n_shapelets` to
   `n_shapelets * n_dims` to ensure feature variability.



   ..
       !! processed by numpydoc !!

   .. py:method:: fit(x, y=None)

      
      Fit the transform.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          BaseAttributeTransform
              This object.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(x, y=None)

      
      Fit the embedding and return the transform of x.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The embedding.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(x)

      
      Transform the dataset.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The transformation.











      ..
          !! processed by numpydoc !!


.. py:class:: DerivativeTransform(method='slope')



   
   Perform derivative transformation on time series data.


   :Parameters:

       **method** : str, optional
           The method to use for the derivative transformation. Must be one of:
           "slope", "central", or "backward".
           
           - "backward", computes the derivative at each point using the
             difference between the current and previous elements.
           - "central", computes the derivative at each point using the average of
             the differences between the next and previous elements.
           - "slope", computes a smoothed derivative at each point by averaging
             the difference between the current and previous elements with half
             the difference between the next and previous elements.














   ..
       !! processed by numpydoc !!

   .. py:method:: fit(X, y=None)

      
      Fit the model to the provided data.

      Only performs input validation.

      :Parameters:

          **X** : array-like of shape (n_samples, n_dims, n_timesteps)
              The input data to fit the model.

          **y** : array-like, optional
              Not used.



      :Returns:

          object
              Returns the instance itself.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(X, y=None, **fit_params)

      
      Fit to data, then transform it.

      Fits transformer to `X` and `y` with optional parameters `fit_params`
      and returns a transformed version of `X`.

      :Parameters:

          **X** : array-like of shape (n_samples, n_features)
              Input samples.

          **y** :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None
              Target values (None for unsupervised transformations).

          **\*\*fit_params** : dict
              Additional fit parameters.



      :Returns:

          **X_new** : ndarray array of shape (n_samples, n_features_new)
              Transformed array.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(X)

      
      Transform the input data using a derivative transformation.


      :Parameters:

          **X** : array-like of shape (n_samples, n_dims, n_timesteps)
              The input data to be transformed.



      :Returns:

          array
              The transformed data.











      ..
          !! processed by numpydoc !!


.. py:class:: DiffTransform(order=1)



   
   A transformer that applies a difference transformation to time series data.


   :Parameters:

       **order** : int, optional
           The order of the difference operation. Default is 1.














   ..
       !! processed by numpydoc !!

   .. py:method:: fit(X, y=None)

      
      Fit the model to the provided data.


      :Parameters:

          **X** : array-like of shape (n_samples, n_dims, n_timesteps)
              The input data to fit the model. Must have at least two timesteps.

          **y** : array-like, optional
              Not used.



      :Returns:

          object
              Returns the instance of the fitted model.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(X, y=None, **fit_params)

      
      Fit to data, then transform it.

      Fits transformer to `X` and `y` with optional parameters `fit_params`
      and returns a transformed version of `X`.

      :Parameters:

          **X** : array-like of shape (n_samples, n_features)
              Input samples.

          **y** :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None
              Target values (None for unsupervised transformations).

          **\*\*fit_params** : dict
              Additional fit parameters.



      :Returns:

          **X_new** : ndarray array of shape (n_samples, n_features_new)
              Transformed array.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(X)

      
      Transform the input data by computing the discrete differences.


      :Parameters:

          **X** : array-like of shape (n_samples, n_dims, n_timesteps)
              The input data to be transformed.



      :Returns:

          array_like
              An array containing the discrete difference of the input data along
              the last axis.











      ..
          !! processed by numpydoc !!


.. py:class:: DilatedShapeletTransform(n_shapelets=1000, *, metric='euclidean', metric_params=None, normalize_prob=0.5, min_shapelet_size=None, max_shapelet_size=None, shapelet_size=None, lower=0.05, upper=0.1, ignore_y=False, random_state=None, n_jobs=None)



   
   Dilated shapelet transform.

   Transform time series to a representation consisting of three
   values per shapelet: minimum dilated distance, the index of
   the timestep that minimizes the distance and number of subsequences
   that are below a distance threshold.

   :Parameters:

       **n_shapelets** : int, optional
           The number of dilated shapelets.

       **metric** : str or callable, optional
           The distance metric
           
           See ``_METRICS.keys()`` for a list of supported metrics.

       **metric_params** : dict, optional
           Parameters to the metric.
           
           Read more about the parameters in the
           :ref:`User guide <list_of_metrics>`.

       **normalize_prob** : float, optional
           The probability of standardizing a shapelet with zero mean and unit
           standard deviation.

       **min_shapelet_size** : float, optional
           The minimum shapelet size. If None, use the discrete sizes
           in `shapelet_size`.

       **max_shapelet_size** : float, optional
           The maximum shapelet size. If None, use the discrete sizes
           in `shapelet_size`.

       **shapelet_size** : array-like, optional
           The size of shapelets, by default [7, 9, 11].

       **lower** : float, optional
           The lower percentile to draw distance thresholds above.

       **upper** : float, optional
           The upper percentile to draw distance thresholds below.

       **ignore_y** : bool, optional
           Ignore `y` and use the same sample which a shapelet is sampled from to
           estimate the distance threshold.

       **random_state** : int or RandomState, optional
           Controls the random sampling of kernels.
           
           - If `int`, `random_state` is the seed used by the random number
             generator.
           - If :class:`numpy.random.RandomState` instance, `random_state` is
             the random number generator.
           - If `None`, the random number generator is the
             :class:`numpy.random.RandomState` instance used by
             :func:`numpy.random`.

       **n_jobs** : int, optional
           The number of parallel jobs.












   .. rubric:: References

   Antoine Guillaume, Christel Vrain, Elloumi Wael
       Random Dilated Shapelet Transform: A New Approach for Time Series Shapelets
       Pattern Recognition and Artificial Intelligence, 2022

   .. only:: latex

      


   ..
       !! processed by numpydoc !!

   .. py:method:: fit(x, y=None)

      
      Fit the transform.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          BaseAttributeTransform
              This object.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(x, y=None)

      
      Fit the embedding and return the transform of x.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The embedding.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(x)

      
      Transform the dataset.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The transformation.











      ..
          !! processed by numpydoc !!


.. py:class:: FeatureTransform(*, summarizer='catch22', n_jobs=None)



   
   Transform a time series as a number of features.


   :Parameters:

       **summarizer** : str or list, optional
           The method to summarize each interval.
           
           - if str, the summarizer is determined by `_SUMMARIZERS.keys()`.
           - if list, the summarizer is a list of functions f(x) -> float, where x
             is a numpy array.
           
           The default summarizer summarizes each time series using `catch22`-features.

       **n_jobs** : int, optional
           The number of cores to use on multi-core.













   .. rubric:: Examples

   >>> from wildboar.datasets import load_gun_point
   >>> X, y = load_gun_point()
   >>> X_t = FeatureTransform().fit_transform(X)
   >>> X_t[0]
   array([-5.19633603e-01, -6.51047206e-01,  1.90000000e+01,  4.80000000e+01,
           7.48441896e-01, -2.73293560e-05,  2.21476510e-01,  4.70000000e+01,
           4.00000000e-02,  0.00000000e+00,  2.70502518e+00,  2.60000000e+01,
           6.42857143e-01,  1.00000000e-01, -3.26666667e-01,  9.89974643e-01,
           2.90000000e+01,  1.31570726e+00,  1.50000000e-01,  8.50000000e-01,
           4.90873852e-02,  1.47311800e-01])

   ..
       !! processed by numpydoc !!

   .. py:method:: fit(x, y=None)

      
      Fit the transform.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          BaseAttributeTransform
              This object.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(x, y=None)

      
      Fit the embedding and return the transform of x.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The embedding.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(x)

      
      Transform the dataset.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The transformation.











      ..
          !! processed by numpydoc !!


.. py:class:: FftTransform



   
   Discrete Fourier Transform.
















   ..
       !! processed by numpydoc !!

   .. py:method:: fit(X, y=None)

      
      Fit the estimator.


      :Parameters:

          **X** : array-like of shape (n_samples, n_dims, n_timesteps)
              The samples.

          **y** : ignore, optional
              Ignored.



      :Returns:

          self
              This instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(X, y=None, **fit_params)

      
      Fit to data, then transform it.

      Fits transformer to `X` and `y` with optional parameters `fit_params`
      and returns a transformed version of `X`.

      :Parameters:

          **X** : array-like of shape (n_samples, n_features)
              Input samples.

          **y** :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None
              Target values (None for unsupervised transformations).

          **\*\*fit_params** : dict
              Additional fit parameters.



      :Returns:

          **X_new** : ndarray array of shape (n_samples, n_features_new)
              Transformed array.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(X)

      
      Transform the input.


      :Parameters:

          **X** : array-like of shape (n_samples, n_dims, n_timesteps)
              The input samples.



      :Returns:

          ndarray of shape (n_samples, n_dims, m_timesteps)
              The transformed data. If n_timesteps is even m_timesteps is
              (n_timesteps/2) + 1; otherwise (n_timesteps + 1) / 2.











      ..
          !! processed by numpydoc !!


.. py:class:: HydraTransform(*, n_groups=64, n_kernels=8, kernel_size=9, sampling='normal', sampling_params=None, n_jobs=None, random_state=None)



   
   A Dictionary based method using convolutional kernels.


   :Parameters:

       **n_groups** : int, optional
           The number of groups of kernels.

       **n_kernels** : int, optional
           The number of kernels per group.

       **kernel_size** : int, optional
           The size of the kernel.

       **sampling** : {"normal"}, optional
           The strategy for sampling kernels. By default kernel weights
           are sampled from a normal distribution with zero mean and unit
           standard deviation.

       **sampling_params** : dict, optional
           Parameters to the sampling approach. The "normal" sampler
           accepts two parameters: `mean` and `scale`.

       **n_jobs** : int, optional
           The number of jobs to run in parallel. A value of `None` means using
           a single core and a value of `-1` means using all cores. Positive
           integers mean the exact number of cores.

       **random_state** : int or RandomState, optional
           Controls the random sampling of kernels.
           
           - If `int`, `random_state` is the seed used by the random number
             generator.
           - If :class:`numpy.random.RandomState` instance, `random_state` is
             the random number generator.
           - If `None`, the random number generator is the
             :class:`numpy.random.RandomState` instance used by
             :func:`numpy.random`.

   :Attributes:

       **embedding_** : Embedding
           The underlying embedding









   .. seealso::

       
       :obj:`HydraClassifier`
           A classifier using hydra transform.
       
       
   .. rubric:: Notes

   The implementation does not implement the first order descrete differences
   described by Dempster et. al. (2023). If this is desired, one can use
   native scikit-learn functionalities and the
   :class:`~wildboar.transform.DiffTransform`:

   >>> from sklearn.pipeline import make_pipeline, make_union
   >>> from wildboar.transform import DiffTransform, HydraTransform
   >>> dempster_hydra = make_union(
   ...     HydraTransform(n_groups=32),
   ...     make_pipeline(
   ...         DiffTransform(),
   ...         HydraTransform(n_groups=32)
   ...     )
   ... )

   .. rubric:: References

   Dempster, A., Schmidt, D. F., & Webb, G. I. (2023).
       Hydra: competing convolutional kernels for fast and accurate
       time series classification. Data Mining and Knowledge Discovery

   .. only:: latex

      

   .. rubric:: Examples

   >>> from wildboar.datasets import load_gun_point
   >>> from wildboar.transform import HydraTransform
   >>> X, y = load_gun_point()
   >>> t = HydraTransform(n_groups=8, n_kernels=4, random_state=1)
   >>> t.fit_transform(X)

   ..
       !! processed by numpydoc !!

   .. py:method:: fit(x, y=None)

      
      Fit the transform.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          BaseAttributeTransform
              This object.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(x, y=None)

      
      Fit the embedding and return the transform of x.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The embedding.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(x)

      
      Transform the dataset.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The transformation.











      ..
          !! processed by numpydoc !!


.. py:class:: IntervalTransform(n_intervals='sqrt', *, intervals='fixed', sample_size=None, depth=None, min_size=0.0, max_size=1.0, coverage_probability=None, variability=1, summarizer='mean_var_slope', summarizer_params=None, n_jobs=None, random_state=None)



   
   Embed a time series as a collection of features per interval.


   :Parameters:

       **n_intervals** : str, int or float, optional
           The number of intervals to use for the transform.
           
           - if "log2", the number of intervals is `log2(n_timestep)`.
           - if "sqrt", the number of intervals is `sqrt(n_timestep)`.
           - if int, the number of intervals is `n_intervals`.
           - if float, the number of intervals is `n_intervals * n_timestep`, with
             `0 < n_intervals < 1`.
           
           .. deprecated:: 1.2
               The option "log" has been renamed to "log2".

       **intervals** : str, optional
           The method for selecting intervals.
           
           - if "fixed", `n_intervals` non-overlapping intervals.
           - if "dyadic", `2**depth-1+2**depth-1-depth" intervals.
           - if "random", `n_intervals` possibly overlapping intervals of randomly
             sampled in `[min_size * n_timestep, max_size * n_timestep]`.
           
           Read more in the :ref:`User Guide <interval_intervals>`

       **sample_size** : float, optional
           The sample size of fixed intervals if `intervals="fixed"`.

       **depth** : int, optional
           The maximum depth for dyadic intervals if `intervals="dyadic"`.

       **min_size** : float, optional
           The minimum interval size if `intervals="random"`. Ignored if
           `coverage_probability` is set.

       **max_size** : float, optional
           The maximum interval size if `intervals="random"`. Ignored if
           `coverage_probability` is set.

       **coverage_probability** : float, optional
           The probability that a time step is covered by an interval, in the
           range 0 < coverage_probability <= 1.
           
           - For larger `coverage_probability`, we get larger intervals.
           - For smaller `coverage_probability`, we get shorter intervals.

       **variability** : float, optional
           Controls the shape of the Beta distribution used to sample intervals.
           Defaults to 1.
           
           - Higher `variability` creates more uniform intervals.
           - Lower `variability` creates more variable intervals sizes.

       **summarizer** : str or list, optional
           The method to summarize each interval.
           
           - if str, the summarizer is determined by `_SUMMARIZERS.keys()`.
           - if list, the summarizer is a list of functions `f(x) -> float`, where
             `x` is a numpy array.
           
           The default summarizer summarizes each interval as its mean, standard
           deviation and slope.
           
           Read more in the :ref:`User Guide <interval_summarizers>`

       **summarizer_params** : dict, optional
           A dictionary of parameters to the summarizer.

       **n_jobs** : int, optional
           The number of cores to use on multi-core.

       **random_state** : int or RandomState, optional
           - If `int`, `random_state` is the seed used by the random number generator
           - If `RandomState` instance, `random_state` is the random number generator
           - If `None`, the random number generator is the `RandomState` instance used
             by `np.random`.











   .. rubric:: Notes

   Parallelization depends on releasing the global interpreter lock (GIL). As
   such, custom functions as summarizers reduces the performance. Wildboar
   implements summarizers for taking the mean ("mean"), variance ("variance")
   and slope ("slope") as well as their combination ("mean_var_slope") and the
   full suite of `catch22` features ("catch22"). In the future, we will allow
   downstream projects to implement their own summarizers in Cython which will
   allow for releasing the GIL.

   .. rubric:: References

   Lubba, Carl H., Sarab S. Sethi, Philip Knaute, Simon R. Schultz,             Ben D. Fulcher, and Nick S. Jones.
       catch22: Canonical time-series characteristics.
       Data Mining and Knowledge Discovery 33, no. 6 (2019): 1821-1852.

   .. only:: latex

      

   .. rubric:: Examples

   >>> from wildboar.datasets import load_dataset
   >>> x, y = load_dataset("GunPoint")
   >>> t = IntervalTransform(n_intervals=10, summarizer="mean")
   >>> t.fit_transform(x)

   Each interval (15 timepoints) are transformed to their mean.

   >>> t = IntervalTransform(n_intervals="sqrt", summarizer=[np.mean, np.std])
   >>> t.fit_transform(x)

   Each interval (`150 // 12` timepoints) are transformed to two features. The
   mean and the standard deviation.

   ..
       !! processed by numpydoc !!

   .. py:method:: fit(x, y=None)

      
      Fit the transform.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          BaseAttributeTransform
              This object.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(x, y=None)

      
      Fit the embedding and return the transform of x.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The embedding.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(x)

      
      Transform the dataset.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The transformation.











      ..
          !! processed by numpydoc !!


.. py:class:: MatrixProfileTransform(window=0.1, exclude=None, n_jobs=None)



   
   Matrix profile transform.

   Transform each time series in a dataset to its MatrixProfile similarity
   self-join.

   :Parameters:

       **window** : int or float, optional
           The subsequence size, by default 0.1.
           
           - if float, a fraction of n_timestep.
           - if int, the exact subsequence size.

       **exclude** : int or float, optional
           The size of the exclusion zone. The default exclusion zone is 0.2.
           
           - if float, expressed as a fraction of the windows size.
           - if int, exact size (0 < exclude).

       **n_jobs** : int, optional
           The number of jobs to use when computing the profile.













   .. rubric:: Examples

   >>> from wildboar.datasets import load_two_lead_ecg()
   >>> from wildboar.transform import MatrixProfileTransform
   >>> x, y = load_two_lead_ecg()
   >>> t = MatrixProfileTransform()
   >>> t.fit_transform(x)

   ..
       !! processed by numpydoc !!

   .. py:method:: fit(x, y=None)

      
      Fit the matrix profile.

      Sets the expected input dimensions.

      :Parameters:

          **x** : array-like of shape (n_samples, n_timesteps)         or (n_samples, n_dims, n_timesteps)
              The samples.

          **y** : ignored
              The optional labels.



      :Returns:

          self
              A fitted instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(X, y=None, **fit_params)

      
      Fit to data, then transform it.

      Fits transformer to `X` and `y` with optional parameters `fit_params`
      and returns a transformed version of `X`.

      :Parameters:

          **X** : array-like of shape (n_samples, n_features)
              Input samples.

          **y** :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None
              Target values (None for unsupervised transformations).

          **\*\*fit_params** : dict
              Additional fit parameters.



      :Returns:

          **X_new** : ndarray array of shape (n_samples, n_features_new)
              Transformed array.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(x)

      
      Transform the samples to their MatrixProfile self-join.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timesteps)         or (n_samples, n_dims, n_timesteps)
              The samples.



      :Returns:

          ndarray of shape (n_samples, n_timestep) or (n_samples, n_dims, n_timesteps)
              The matrix matrix profile of each sample.











      ..
          !! processed by numpydoc !!


.. py:class:: PAA(n_intervals='sqrt', window=None)



   
   Peicewise aggregate approximation.


   :Parameters:

       **n_intervals** : {"sqrt", "log2"}, int or float, optional
           The number of intervals.

       **window** : int, optional
           The size of an interval. If `window`, is given then `n_intervals` is ignored.














   ..
       !! processed by numpydoc !!

   .. py:method:: fit_transform(X, y=None, **fit_params)

      
      Fit to data, then transform it.

      Fits transformer to `X` and `y` with optional parameters `fit_params`
      and returns a transformed version of `X`.

      :Parameters:

          **X** : array-like of shape (n_samples, n_features)
              Input samples.

          **y** :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None
              Target values (None for unsupervised transformations).

          **\*\*fit_params** : dict
              Additional fit parameters.



      :Returns:

          **X_new** : ndarray array of shape (n_samples, n_features_new)
              Transformed array.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


.. py:class:: PivotTransform(n_pivots=100, *, metric='auto', metric_params=None, metric_sample=None, random_state=None, n_jobs=None)



   
   A transform using pivot time series and sampled distance metrics.


   :Parameters:

       **n_pivots** : int, optional
           The number of pivot time series.

       **metric** : {'auto'} or list, optional
           - If str, the metric to compute the distance.
           - If list, multiple metrics specified as a list of tuples, where the first
               element of the tuple is a metric name and the second element a dictionary
               with a parameter grid specification. A parameter grid specification is a
               dict with two mandatory and one optional key-value pairs defining the
               lower and upper bound on the values and number of values in the grid. For
               example, to specifiy a grid over the argument 'r' with 10 values in the
               range 0 to 1, we would give the following specification: `dict(min_r=0,
               max_r=1, num_r=10)`.
           
           Read more about the metrics and their parameters in the :ref:`User guide
           <list_of_subsequence_metrics>`.

       **metric_params** : dict, optional
           Parameters for the distance measure. Ignored unless metric is a string.
           
           Read more about the parameters in the :ref:`User guide <list_of_metrics>`.

       **metric_sample** : {"uniform", "weighted"}, optional
           If multiple metrics are specified this parameter controls how they are
           sampled. "uniform" samples each metric configuration with equal probability
           and "weighted" samples each metric with equal probability. By default,
           metric configurations are sampled with equal probability.

       **random_state** : int or np.RandomState, optional
           The random state.

       **n_jobs** : int, optional
           The number of cores to use.














   ..
       !! processed by numpydoc !!

   .. py:method:: fit(x, y=None)

      
      Fit the transform.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          BaseAttributeTransform
              This object.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(x, y=None)

      
      Fit the embedding and return the transform of x.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The embedding.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(x)

      
      Transform the dataset.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The transformation.











      ..
          !! processed by numpydoc !!


.. py:class:: ProximityTransform(n_pivots=100, metric='auto', metric_params=None, metric_sample='weighted', random_state=None, n_jobs=None)



   
   Transform time series based on class conditional pivots.


   :Parameters:

       **n_pivots** : int, optional
           The number of pivot time series per class.

       **metric** : {'auto'} or list, optional
           - If str, the metric to compute the distance.
           - If list, multiple metrics specified as a list of tuples, where the first
               element of the tuple is a metric name and the second element a dictionary
               with a parameter grid specification. A parameter grid specification is a
               dict with two mandatory and one optional key-value pairs defining the
               lower and upper bound on the values and number of values in the grid. For
               example, to specifiy a grid over the argument 'r' with 10 values in the
               range 0 to 1, we would give the following specification: `dict(min_r=0,
               max_r=1, num_r=10)`.
           
           Read more about the metrics and their parameters in the :ref:`User guide
           <list_of_subsequence_metrics>`.

       **metric_params** : dict, optional
           Parameters for the distance measure. Ignored unless metric is a string.
           
           Read more about the parameters in the :ref:`User guide <list_of_metrics>`.

       **metric_sample** : {"uniform", "weighted"}, optional
           If multiple metrics are specified this parameter controls how they are
           sampled. "uniform" samples each metric configuration with equal probability
           and "weighted" samples each metric with equal probability. By default,
           metric configurations are sampled with equal probability.

       **random_state** : int or np.RandomState, optional
           The random state.

       **n_jobs** : int, optional
           The number of cores to use.














   ..
       !! processed by numpydoc !!

   .. py:method:: fit_transform(X, y=None, **fit_params)

      
      Fit to data, then transform it.

      Fits transformer to `X` and `y` with optional parameters `fit_params`
      and returns a transformed version of `X`.

      :Parameters:

          **X** : array-like of shape (n_samples, n_features)
              Input samples.

          **y** :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None
              Target values (None for unsupervised transformations).

          **\*\*fit_params** : dict
              Additional fit parameters.



      :Returns:

          **X_new** : ndarray array of shape (n_samples, n_features_new)
              Transformed array.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


.. py:class:: QuantTransform(depth='auto', v=4, n_jobs=None)



   
   Quant transformation

   Computes quantiles over a fixed set of intervals on input time series
   and their transformations, using these quantiles for classification.

   The Quant transform performs the following steps:

   1. Computes quantiles over fixed, dyadic intervals on the input time
      series.
   2. Applies three transformations to the time series (first difference,
      second difference, and Fourier transform).

   :Parameters:

       **depth** : {"auto"} or int, optional
           The maximal depth. If set to auto, the depth is `min(log2(n_timestep) +
           1, 6)`.

       **v** : int, optional
           The proportion of quantiles per interval given as `k = m/v` were `m` is
           the length of the interval.

       **n_jobs** : int, optional
           The number of parallel jobs.











   .. rubric:: Notes

   The implementation differs to the original in the following ways:

   1. Does not apply smoothing to the first order difference.
   2. Does not subtract the mean from every second quantile.
   3. Does not apply 1-order differences if the time series are shorter than 2
      timesteps.
   4. Does not apply 2-order differences if the time series are shorter than 3
      timesteps.

   .. rubric:: References

   Dempster, Angus, Daniel F. Schmidt, and Geoffrey I. Webb.
       "Quant: A Minimalist Interval Method for Time Series Classification."
       Data Mining and Knowledge Discovery 38, no. 4 (July 1, 2024): 23772402.
       https://doi.org/10.1007/s10618-024-01036-9.

   .. only:: latex

      


   ..
       !! processed by numpydoc !!

   .. py:method:: fit(X, y=None)

      
      Fit the transform.


      :Parameters:

          **X** : array-like of shape (n_samples, n_dims, n_timestep)
              The input data.

          **y** : ignored
              ..



      :Returns:

          self
              The fitted estimator.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(X, y=None, **fit_params)

      
      Fit to data, then transform it.

      Fits transformer to `X` and `y` with optional parameters `fit_params`
      and returns a transformed version of `X`.

      :Parameters:

          **X** : array-like of shape (n_samples, n_features)
              Input samples.

          **y** :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None
              Target values (None for unsupervised transformations).

          **\*\*fit_params** : dict
              Additional fit parameters.



      :Returns:

          **X_new** : ndarray array of shape (n_samples, n_features_new)
              Transformed array.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(X)

      
      Transform the input samples.


      :Parameters:

          **X** : array-like of shape (n_samples, n_dims, n_timestep)
              The input data.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The transformed samples.











      ..
          !! processed by numpydoc !!


.. py:class:: RandomShapeletTransform(n_shapelets=1000, *, metric='euclidean', metric_params=None, min_shapelet_size=0.0, max_shapelet_size=1.0, n_jobs=None, random_state=None)



   
   Random shapelet tranform.

   Transform a time series to the distances to a selection of random
   shapelets.

   :Parameters:

       **n_shapelets** : int, optional
           The number of shapelets in the resulting transform.

       **metric** : str or list, optional
           - If str, the distance metric used to identify the best shapelet.
           - If list, multiple metrics specified as a list of tuples, where the first
               element of the tuple is a metric name and the second element a dictionary
               with a parameter grid specification. A parameter grid specification is a
               dict with two mandatory and one optional key-value pairs defining the
               lower and upper bound on the values and number of values in the grid. For
               example, to specifiy a grid over the argument 'r' with 10 values in the
               range 0 to 1, we would give the following specification: ``dict(min_r=0,
               max_r=1, num_r=10)``.
           
           Read more about the metrics and their parameters in the
           :ref:`User guide <list_of_subsequence_metrics>`.

       **metric_params** : dict, optional
           Parameters for the distance measure. Ignored unless metric is a string.
           
           Read more about the parameters in the :ref:`User guide
           <list_of_subsequence_metrics>`.

       **min_shapelet_size** : float, optional
           Minimum shapelet size.

       **max_shapelet_size** : float, optional
           Maximum shapelet size.

       **n_jobs** : int, optional
           The number of jobs to run in parallel. None means 1 and -1 means using all
           processors.

       **random_state** : int or RandomState, optional
           - If `int`, `random_state` is the seed used by the random number generator
           - If `RandomState` instance, `random_state` is the random number generator
           - If `None`, the random number generator is the `RandomState` instance used
               by `np.random`.

   :Attributes:

       **embedding_** : Embedding
           The underlying embedding object.











   .. rubric:: References

   Wistuba, Martin, Josif Grabocka, and Lars Schmidt-Thieme.
       Ultra-fast shapelets for time series classification. arXiv preprint
       arXiv:1503.05018 (2015).

   .. only:: latex

      

   .. rubric:: Examples

   Transform each time series to the minimum DTW distance to each shapelet

   >>> from wildboar.dataset import load_gunpoint()
   >>> from wildboar.transform import RandomShapeletTransform
   >>> t = RandomShapeletTransform(metric="dtw")
   >>> t.fit_transform(X)

   Transform each time series to the either the minimum DTW distance, with r randomly
   set set between 0 and 1 or ERP distance with g between 0 and 1.

   >>> t = RandomShapeletTransform(
   ...     metric=[
   ...         ("dtw", dict(min_r=0.0, max_r=1.0)),
   ...         ("erp", dict(min_g=0.0, max_g=1.0)),
   ...     ]
   ... )
   >>> t.fit_transform(X)

   ..
       !! processed by numpydoc !!

   .. py:method:: fit(x, y=None)

      
      Fit the transform.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          BaseAttributeTransform
              This object.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(x, y=None)

      
      Fit the embedding and return the transform of x.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The embedding.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(x)

      
      Transform the dataset.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The transformation.











      ..
          !! processed by numpydoc !!


.. py:class:: RocketTransform(n_kernels=1000, *, sampling='normal', sampling_params=None, kernel_size=None, min_size=None, max_size=None, bias_prob=1.0, normalize_prob=1.0, padding_prob=0.5, n_jobs=None, random_state=None)



   
   Transform a time series using random convolution features.


   :Parameters:

       **n_kernels** : int, optional
           The number of kernels to sample at each node.

       **sampling** : {"normal", "uniform", "shapelet"}, optional
           The sampling of convolutional filters.
           
           - if "normal", sample filter according to a normal distribution with
             ``mean`` and ``scale``.
           - if "uniform", sample filter according to a uniform distribution with
             ``lower`` and ``upper``.
           - if "shapelet", sample filters as subsequences in the training data.

       **sampling_params** : dict, optional
           Parameters for the sampling strategy.
           
           - if "normal", ``{"mean": float, "scale": float}``, defaults to
             ``{"mean": 0, "scale": 1}``.
           - if "uniform", ``{"lower": float, "upper": float}``, defaults to
             ``{"lower": -1, "upper": 1}``.

       **kernel_size** : array-like, optional
           The kernel size, by default ``[7, 11, 13]``.

       **min_size** : float, optional
           The minimum timestep size used for generating kernel sizes, If set,
           ``kernel_size`` is ignored.

       **max_size** : float, optional
           The maximum timestep size used for generating kernel sizes, If set,
           ``kernel_size`` is ignored.

       **bias_prob** : float, optional
           The probability of using the bias term.

       **normalize_prob** : float, optional
           The probability of performing normalization.

       **padding_prob** : float, optional
           The probability of padding with zeros.

       **n_jobs** : int, optional
           The number of jobs to run in parallel. A value of ``None`` means using
           a single core and a value of ``-1`` means using all cores. Positive
           integers mean the exact number of cores.

       **random_state** : int or RandomState, optional
           Controls the random resampling of the original dataset.
           
           - If ``int``, ``random_state`` is the seed used by the random number
             generator.
           - If :class:`numpy.random.RandomState` instance, ``random_state`` is
             the random number generator.
           - If ``None``, the random number generator is the
             :class:`numpy.random.RandomState` instance used by
             :func:`numpy.random`.

   :Attributes:

       **embedding_** : Embedding
           The underlying embedding











   .. rubric:: References

   Dempster, Angus, Franois Petitjean, and Geoffrey I. Webb.
       ROCKET: exceptionally fast and accurate time series classification using
       random convolutional kernels.
       Data Mining and Knowledge Discovery 34.5 (2020): 1454-1495.

   .. only:: latex

      

   .. rubric:: Examples

   >>> from wildboar.datasets import load_gun_point
   >>> from wildboar.transform import RocketTransform
   >>> X, y = load_gun_point()
   >>> t = RocketTransform(n_kernels=10, random_state=1)
   >>> t.fit_transform(X)
   array([[0.51333333, 5.11526939, 0.47333333, ..., 2.04712544, 0.24      ,
           0.82912261],
          [0.52666667, 5.26611524, 0.54      , ..., 1.98047216, 0.24      ,
           0.81260641],
          [0.54666667, 4.71210092, 0.35333333, ..., 2.28841158, 0.25333333,
           0.82203705],
          ...,
          [0.54666667, 4.72938203, 0.45333333, ..., 2.53756324, 0.24666667,
           0.8380654 ],
          [0.68666667, 3.80533684, 0.26      , ..., 2.41709413, 0.25333333,
           0.65634235],
          [0.66      , 3.94724793, 0.32666667, ..., 1.85575661, 0.25333333,
           0.67630249]])

   ..
       !! processed by numpydoc !!

   .. py:method:: fit(x, y=None)

      
      Fit the transform.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          BaseAttributeTransform
              This object.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(x, y=None)

      
      Fit the embedding and return the transform of x.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The embedding.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(x)

      
      Transform the dataset.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The transformation.











      ..
          !! processed by numpydoc !!


.. py:class:: SAX(*, n_intervals='sqrt', window=None, n_bins=4, binning='normal', estimate='deprecated', scale=True)



   
   Symbolic aggregate approximation.


   :Parameters:

       **n_intervals** : str, optional
           The number of intervals to use for the transform.
           
           - if "log2", the number of intervals is `log2(n_timestep)`.
           - if "sqrt", the number of intervals is `sqrt(n_timestep)`.
           - if int, the number of intervals is `n_intervals`.
           - if float, the number of intervals is `n_intervals * n_timestep`, with
               `0 < n_intervals < 1`.

       **window** : int, optional
           The window size. If `window` is set, the value of `n_intervals` has no
           effect.

       **n_bins** : int, optional
           The number of bins.

       **binning** : str, optional
           The bin construction. By default the bins are defined according to the
           normal distribution. Possible values are "normal" for normally
           distributed bins or "uniform" for uniformly distributed bins.

       **estimate** : bool, optional
           Estimate the distribution parameters for the binning from data.
           
           If `estimate=False`, it is assumed that each time series is
           preprocessed using:
           
           - :func:`datasets.preprocess.normalize` when `binning="normal"`.
           - :func:`datasets.preprocess.minmax_scale`. when `binning="uniform"`.

       **scale** : bool, optional
           Ensure that the input is correctly scaled.
           
           If `scale=False`, it is assumed that each time series is
           preprocessed using:
           
           - :func:`datasets.preprocess.normalize` when `binning="normal"`.
           - :func:`datasets.preprocess.minmax_scale` when `binning="uniform"`.














   ..
       !! processed by numpydoc !!

   .. py:method:: fit_transform(X, y=None, **fit_params)

      
      Fit to data, then transform it.

      Fits transformer to `X` and `y` with optional parameters `fit_params`
      and returns a transformed version of `X`.

      :Parameters:

          **X** : array-like of shape (n_samples, n_features)
              Input samples.

          **y** :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None
              Target values (None for unsupervised transformations).

          **\*\*fit_params** : dict
              Additional fit parameters.



      :Returns:

          **X_new** : ndarray array of shape (n_samples, n_features_new)
              Transformed array.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


.. py:class:: ShapeletTransform(n_shapelets='auto', *, metric='euclidean', metric_params=None, strategy='random', shapelet_size=0.1, sample_size=1.0, min_shapelet_size=0.0, max_shapelet_size=1.0, coverage_probability=None, variability=None, random_state=None, n_jobs=None)



   
   Shapelet Transform.

   Transform a time series to the distances to a selection of shapelets. The
   transform is unsupervised if `strategy="random"` and supervised if
   `strategy="best"`.

   :Parameters:

       **n_shapelets** : int or {"log2", "sqrt", "auto"}, optional
           The number of shapelets in the resulting transform.
           
           - if, "auto" the number of shapelets depend on the value of `strategy`.
             For "best" the number is 1; and for "random" it is 1000.
           - if, "log2", the number of shaplets is the log2 of the total possible
             number of shapelets.
           - if, "sqrt", the number of shaplets is the square root of the total
             possible number of shapelets.

       **metric** : str or list, optional
           - If str, the distance metric used to identify the best shapelet.
           - If list, multiple metrics specified as a list of tuples, where the first
               element of the tuple is a metric name and the second element a dictionary
               with a parameter grid specification. A parameter grid specification is a
               dict with two mandatory and one optional key-value pairs defining the
               lower and upper bound on the values and number of values in the grid. For
               example, to specify a grid over the argument 'r' with 10 values in the
               range 0 to 1, we would give the following specification: ``dict(min_r=0,
               max_r=1, num_r=10)``.
           
           Read more about the metrics and their parameters in the
           :ref:`User guide <list_of_subsequence_metrics>`.
           
           .. warning::
               Multiple metrics are only supported if `strategy="random"`.

       **metric_params** : dict, optional
           Parameters for the distance measure. Ignored unless metric is a string.
           
           Read more about the parameters in the :ref:`User guide
           <list_of_subsequence_metrics>`.

       **strategy** : {"best", "random"}, optional
           The strategy for selecting shapelets.
           
           - If "random", `n_shapelets` shapelets are randomly selected in the
             range defined by `min_shapelet_size` and `max_shapelet_size`
           - If "best", `n_shapelets` shapelets are selected per input sample
             of the size determined by `shapelet_size`.
           
           If strategy is set to "best", the transformation is supervised and requires
           `y`.

       **shapelet_size** : int, float or array-like, optional
           The shapelet size if `strategy="best"`.
           
           - If int, the exact shapelet size.
           - If float, a fraction of the number of input timestep.
           - If array-like, a list of float or int.

       **sample_size** : float, optional
           The size of the sample to determine the shapelets, if `shapelet_size="best"`.

       **min_shapelet_size** : float, optional
           Minimum shapelet size.

       **max_shapelet_size** : float, optional
           Maximum shapelet size.

       **coverage_probability** : float, optional
           The probability that a time step is covered by a
           shapelet, in the range 0 < coverage_probability <= 1.
           
           - For larger `coverage_probability`, we get larger shapelets.
           - For smaller `coverage_probability`, we get shorter shapelets.

       **variability** : float, optional
           Controls the shape of the Beta distribution used to
           sample shapelets. Defaults to 1.
           
           - Higher `variability` creates more uniform intervals.
           - Lower `variability` creates more variable intervals sizes.

       **random_state** : int or RandomState, optional
           - If `int`, `random_state` is the seed used by the random number generator
           - If `RandomState` instance, `random_state` is the random number generator
           - If `None`, the random number generator is the `RandomState` instance used
               by `np.random`.

       **n_jobs** : int, optional
           The number of jobs to run in parallel. None means 1 and -1 means using all
           processors.

   :Attributes:

       **embedding_** : Embedding
           The underlying embedding object.











   .. rubric:: References

   Wistuba, Martin, Josif Grabocka, and Lars Schmidt-Thieme.
       Ultra-fast shapelets for time series classification. arXiv preprint
       arXiv:1503.05018 (2015).

   .. only:: latex

      

   .. rubric:: Examples

   Transform each time series to the minimum DTW distance to each shapelet

   >>> from wildboar.dataset import load_gunpoint()
   >>> from wildboar.transform import ShapeletTransform
   >>> t = ShapeletTransform(metric="dtw")
   >>> t.fit_transform(X)

   Transform each time series to the either the minimum DTW distance, with r randomly
   set set between 0 and 1 or ERP distance with g between 0 and 1.

   >>> t = ShapeletTransform(
   ...     metric=[
   ...         ("dtw", dict(min_r=0.0, max_r=1.0)),
   ...         ("erp", dict(min_g=0.0, max_g=1.0)),
   ...     ]
   ... )
   >>> t.fit_transform(X)

   Transform each time series to the scaled euclidean distance between the most
   promising shapelet of size 38:

   >>> t = ShapeletTransform(strategy="best", shapelet_size=38)
   >>> t.fit_transform(X, y)

   ..
       !! processed by numpydoc !!

   .. py:method:: fit(x, y=None)

      
      Fit the transform.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          BaseAttributeTransform
              This object.











      ..
          !! processed by numpydoc !!


   .. py:method:: fit_transform(x, y=None)

      
      Fit the embedding and return the transform of x.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.

          **y** : None, optional
              For compatibility.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The embedding.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_metadata_routing()

      
      Get metadata routing of this object.

      Please check :ref:`User Guide <metadata_routing>` on how the routing
      mechanism works.




      :Returns:

          **routing** : MetadataRequest
              A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating
              routing information.











      ..
          !! processed by numpydoc !!


   .. py:method:: get_params(deep=True)

      
      Get parameters for this estimator.


      :Parameters:

          **deep** : bool, default=True
              If True, will return the parameters for this estimator and
              contained subobjects that are estimators.



      :Returns:

          **params** : dict
              Parameter names mapped to their values.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_output(*, transform=None)

      
      Set output container.

      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`
      for an example on how to use the API.

      :Parameters:

          **transform** : {"default", "pandas", "polars"}, default=None
              Configure output of `transform` and `fit_transform`.
              
              - `"default"`: Default output format of a transformer
              - `"pandas"`: DataFrame output
              - `"polars"`: Polars output
              - `None`: Transform configuration is unchanged
              
              .. versionadded:: 1.4
                  `"polars"` option was added.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: set_params(**params)

      
      Set the parameters of this estimator.

      The method works on simple estimators as well as on nested objects
      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have
      parameters of the form ``<component>__<parameter>`` so that it's
      possible to update each component of a nested object.

      :Parameters:

          **\*\*params** : dict
              Estimator parameters.



      :Returns:

          **self** : estimator instance
              Estimator instance.











      ..
          !! processed by numpydoc !!


   .. py:method:: transform(x)

      
      Transform the dataset.


      :Parameters:

          **x** : array-like of shape (n_samples, n_timestep) or                (n_samples, n_dimensions, n_timestep)
              The time series dataset.



      :Returns:

          ndarray of shape (n_samples, n_outputs)
              The transformation.











      ..
          !! processed by numpydoc !!


.. py:function:: convolve(X, kernel, bias=0.0, *, dilation=1, stride=1, padding=0)

   
   Apply 1D convolution over a time series.


   :Parameters:

       **X** : array-like of shape (n_samples, n_timestep)
           The input.

       **kernel** : array-like of shape (kernel_size, )
           The kernel.

       **bias** : float, optional
           The bias.

       **dilation** : int, optional
           The spacing between kernel elements.

       **stride** : int, optional
           The stride of the convolving kernel.

       **padding** : int, optional
           Implicit padding on both sides of the input time series.



   :Returns:

       ndarray of shape (n_samples, output_size)
           The result of the convolution, where output_size is given by:::
           
               floor(
                   ((X.shape[1] + 2 * padding) - (kernel.shape[0] - 1 * dilation + 1)) / stride
                   + 1
               ).











   ..
       !! processed by numpydoc !!

.. py:function:: piecewice_aggregate_approximation(x, *, n_intervals='sqrt', window=None)

   
   Peicewise aggregate approximation.


   :Parameters:

       **x** : array-like of shape (n_samples, n_timestep)
           The input data.

       **n_intervals** : str, optional
           The number of intervals to use for the transform.
           
           - if "log2", the number of intervals is ``log2(n_timestep)``.
           - if "sqrt", the number of intervals is ``sqrt(n_timestep)``.
           - if int, the number of intervals is ``n_intervals``.
           - if float, the number of intervals is ``n_intervals * n_timestep``, with
               ``0 < n_intervals < 1``.

       **window** : int, optional
           The window size. If ``window`` is set, the value of ``n_intervals`` has no
           effect.



   :Returns:

       ndarray of shape (n_samples, n_intervals)
           The symbolic aggregate approximation.











   ..
       !! processed by numpydoc !!

.. py:function:: symbolic_aggregate_approximation(x, *, n_intervals='sqrt', window=None, n_bins=4, binning='normal')

   
   Symbolic aggregate approximation.


   :Parameters:

       **x** : array-like of shape (n_samples, n_timestep)
           The input data.

       **n_intervals** : str, optional
           The number of intervals to use for the transform.
           
           - if "log2", the number of intervals is ``log2(n_timestep)``.
           - if "sqrt", the number of intervals is ``sqrt(n_timestep)``.
           - if int, the number of intervals is ``n_intervals``.
           - if float, the number of intervals is ``n_intervals * n_timestep``, with
               ``0 < n_intervals < 1``.

       **window** : int, optional
           The window size. If ``window`` is set, the value of ``n_intervals`` has no
           effect.

       **n_bins** : int, optional
           The number of bins.

       **binning** : str, optional
           The bin construction. By default the bins are defined according to the
           normal distribution. Possible values are ``"normal"`` for normally
           distributed bins or ``"uniform"`` for uniformly distributed bins.



   :Returns:

       ndarray of shape (n_samples, n_intervals)
           The symbolic aggregate approximation.











   ..
       !! processed by numpydoc !!

