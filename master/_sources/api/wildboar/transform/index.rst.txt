:py:mod:`wildboar.transform`
============================

.. py:module:: wildboar.transform

.. autoapi-nested-parse::

   Transform raw time series to tabular representations.



Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   catch22/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   wildboar.transform.FeatureTransform
   wildboar.transform.IntervalTransform
   wildboar.transform.MatrixProfileTransform
   wildboar.transform.PAA
   wildboar.transform.PivotTransform
   wildboar.transform.ProximityTransform
   wildboar.transform.RandomShapeletTransform
   wildboar.transform.RocketTransform
   wildboar.transform.SAX



Functions
~~~~~~~~~

.. autoapisummary::

   wildboar.transform.piecewice_aggregate_approximation
   wildboar.transform.symbolic_aggregate_approximation



.. py:class:: FeatureTransform(*, summarizer='catch22', n_jobs=None)

   Bases: :py:obj:`IntervalTransform`

   Transform a time series as a number of features.

   Construct a new feature transform.

   :param summarizer: The method to summarize each interval.

                      - if str, the summarizer is determined by `_SUMMARIZERS.keys()`.
                      - if list, the summarizer is a list of functions f(x) -> float, where
                        x is a numpy array.

                      The default summarizer summarizes each time series using catch22-features
   :type summarizer: str or list, optional
   :param n_jobs: The number of cores to use on multi-core.
   :type n_jobs: int, optional

   .. rubric:: References

   ==========
   Lubba, Carl H., Sarab S. Sethi, Philip Knaute, Simon R. Schultz,         Ben D. Fulcher, and Nick S. Jones.
       catch22: Canonical time-series characteristics.
       Data Mining and Knowledge Discovery 33, no. 6 (2019): 1821-1852.


.. py:class:: IntervalTransform(n_intervals='sqrt', *, intervals='fixed', sample_size=0.5, min_size=0.0, max_size=1.0, summarizer='mean_var_slope', n_jobs=None, random_state=None)

   Bases: :py:obj:`IntervalMixin`, :py:obj:`wildboar.transform._base.BaseFeatureEngineerTransform`

   Embed a time series as a collection of features per interval.

   .. rubric:: Examples

   >>> from wildboar.datasets import load_dataset
   >>> x, y = load_dataset("GunPoint")
   >>> t = IntervalTransform(n_intervals=10, summarizer="mean")
   >>> t.fit_transform(x)

   Each interval (15 timepoints) are transformed to their mean.

   >>> t = IntervalTransform(n_intervals="sqrt", summarizer=[np.mean, np.std])
   >>> t.fit_transform(x)

   Each interval (150 // 12 timepoints) are transformed to two features. The mean
   and the standard deviation.

   Construct a new interval transform.

   :param n_intervals: The number of intervals to use for the transform.

                       - if "log2", the number of intervals is ``log2(n_timestep)``.
                       - if "sqrt", the number of intervals is ``sqrt(n_timestep)``.
                       - if int, the number of intervals is ``n_intervals``.
                       - if float, the number of intervals is ``n_intervals * n_timestep``, with
                         ``0 < n_intervals < 1``.
   :type n_intervals: str, int or float, optional
   :param intervals: The method for selecting intervals

                     - if "fixed", `n_intervals` non-overlapping intervals.
                     - if "sample", ``n_intervals * sample_size`` non-overlapping intervals.
                     - if "random", `n_intervals` possibly overlapping intervals of randomly
                       sampled in ``[min_size * n_timestep, max_size * n_timestep]``
   :type intervals: str, optional
   :param sample_size: The sample size of fixed intervals if ``intervals="sample"``
   :type sample_size: float, optional
   :param min_size: The minimum interval size if ``intervals="random"``
   :type min_size: float, optional
   :param max_size: The maximum interval size if ``intervals="random"``
   :type max_size: float, optional
   :param summarizer: The method to summarize each interval.

                      - if str, the summarizer is determined by ``_SUMMARIZERS.keys()``.
                      - if list, the summarizer is a list of functions ``f(x) -> float``, where
                        x is a numpy array.

                      The default summarizer summarizes each interval as its mean, standard
                      deviation and slope.
   :type summarizer: str or list, optional
   :param n_jobs: The number of cores to use on multi-core.
   :type n_jobs: int, optional
   :param random_state:
                        - If `int`, `random_state` is the seed used by the random number generator
                        - If `RandomState` instance, `random_state` is the random number generator
                        - If `None`, the random number generator is the `RandomState` instance used
                          by `np.random`.
   :type random_state: int or RandomState


.. py:class:: MatrixProfileTransform(window=0.1, exclude=None, n_jobs=None)

   Bases: :py:obj:`sklearn.base.TransformerMixin`, :py:obj:`wildboar.base.BaseEstimator`

   Matrix profile transform.

   Transform each time series in a dataset to its MatrixProfile similarity
   self-join.

   .. rubric:: Examples

   >>> from wildboar.datasets import load_two_lead_ecg()
   >>> from wildboar.transform import MatrixProfileTransform
   >>> x, y = load_two_lead_ecg()
   >>> t = MatrixProfileTransform()
   >>> t.fit_transform(x)

   Construct a new matrix profile transform.

   :param window: The subsequence size, by default 0.1.

                  - if float, a fraction of n_timestep.
                  - if int, the exact subsequence size.
   :type window: int or float, optional
   :param exclude: The size of the exclusion zone. The default exclusion zone is 0.2.

                   - if float, expressed as a fraction of the windows size.
                   - if int, exact size (0 < exclude).
   :type exclude: int or float, optional
   :param n_jobs: The number of jobs to use when computing the profile.
   :type n_jobs: int, optional

   .. py:method:: fit(x, y=None)

      Fit the matrix profile.

      Sets the expected input dimensions.

      :param x: The samples
      :type x: array-like of shape (n_samples, n_timesteps)         or (n_samples, n_dims, n_timesteps)
      :param y: The optional labels.
      :type y: ignored

      :returns: **self**
      :rtype: a fitted instance


   .. py:method:: transform(x)

      Transform the samples to their MatrixProfile self-join.

      :param x: The samples
      :type x: array-like of shape (n_samples, n_timesteps)         or (n_samples, n_dims, n_timesteps)

      :returns: **mp** -- The matrix matrix profile of each sample
      :rtype: ndarray of shape (n_samples, n_timestep)         or (n_samples, n_dims, n_timesteps)



.. py:class:: PAA(n_intervals='sqrt', window=None)

   Bases: :py:obj:`sklearn.base.TransformerMixin`, :py:obj:`wildboar.base.BaseEstimator`

   Peicewise aggregate approximation.

   .. py:property:: intervals


   .. py:method:: fit(x, y=None)


   .. py:method:: inverse_transform(x)


   .. py:method:: transform(x)



.. py:class:: PivotTransform(n_pivots=100, *, metric='auto', metric_params=None, metric_sample=None, random_state=None, n_jobs=None)

   Bases: :py:obj:`PivotMixin`, :py:obj:`wildboar.transform._base.BaseFeatureEngineerTransform`

   A transform using pivot time series and sampled distance metrics.

   Construct a new pivot transform.

   :param n_pivot: The number of pivot time series.
   :type n_pivot: int, optional
   :param metric:
                  - If str, the metric to compute the distance.
                  - If list, multiple metrics specified as a list of tuples, where the first
                    element of the tuple is a metric name and the second element a dictionary
                    with a parameter grid specification. A parameter grid specification is a
                    dict with two mandatory and one optional key-value pairs defining the
                    lower and upper bound on the values and number of values in the grid. For
                    example, to specifiy a grid over the argument 'r' with 10 values in the
                    range 0 to 1, we would give the following specification: ``dict(min_r=0,
                    max_r=1, num_r=10)``.

                  Read more about the metrics and their parameters in the :ref:`User guide
                  <list_of_subsequence_metrics>`.
   :type metric: {'auto'} or list, optional
   :param metric_params: Parameters for the distance measure. Ignored unless metric is a string.

                         Read more about the parameters in the :ref:`User guide <list_of_metrics>`.
   :type metric_params: dict, optional
   :param metric_sample: If multiple metrics are specified this parameter controls how they are
                         sampled. "uniform" samples each metric configuration with equal probability
                         and "weighted" samples each metric with equal probability. By default,
                         metric configurations are sampled with equal probability.
   :type metric_sample: {"uniform", "weighted"}, optional
   :param random_state: The random state
   :type random_state: int or np.RandomState, optional
   :param n_jobs: The number of cores to use.
   :type n_jobs: int, optional


.. py:class:: ProximityTransform(n_pivots=100, metric='auto', metric_params=None, metric_sample='weighted', random_state=None, n_jobs=None)

   Bases: :py:obj:`sklearn.base.TransformerMixin`, :py:obj:`wildboar.base.BaseEstimator`

   Mixin class for all transformers in scikit-learn.

   If :term:`get_feature_names_out` is defined, then `BaseEstimator` will
   automatically wrap `transform` and `fit_transform` to follow the `set_output`
   API. See the :ref:`developer_api_set_output` for details.

   :class:`base.OneToOneFeatureMixin` and
   :class:`base.ClassNamePrefixFeaturesOutMixin` are helpful mixins for
   defining :term:`get_feature_names_out`.

   .. py:method:: fit(X, y)


   .. py:method:: transform(X, y=None)



.. py:class:: RandomShapeletTransform(n_shapelets=1000, *, metric='euclidean', metric_params=None, min_shapelet_size=0.0, max_shapelet_size=1.0, n_jobs=None, random_state=None)

   Bases: :py:obj:`ShapeletMixin`, :py:obj:`wildboar.transform._base.BaseFeatureEngineerTransform`

   Random shapelet tranform.

   Transform a time series to the distances to a selection of random
   shapelets.

   .. attribute:: embedding_

      The underlying embedding object.

      :type: Embedding

   .. rubric:: Examples

   Transform each time series to the minimum DTW distance to each shapelet

   >>> from wildboar.dataset import load_gunpoint()
   >>> from wildboar.transform import RandomShapeletTransform
   >>> t = RandomShapeletTransform(metric="dtw")
   >>> t.fit_transform(X)

   Transform each time series to the either the minimum DTW distance, with r randomly
   set set between 0 and 1 or ERP distance with g between 0 and 1.

   >>> t = RandomShapeletTransform(
   ...     metric=[
   ...         ("dtw", dict(min_r=0.0, max_r=1.0)),
   ...         ("erp", dict(min_g=0.0, max_g=1.0)),
   ...     ]
   ... )
   >>> t.fit_transform(X)

   .. rubric:: References

   Wistuba, Martin, Josif Grabocka, and Lars Schmidt-Thieme.
       Ultra-fast shapelets for time series classification. arXiv preprint
       arXiv:1503.05018 (2015).

   Construct a new random shapelet transform.

   :param n_shapelets: The number of shapelets in the resulting transform.
   :type n_shapelets: int, optional
   :param metric:
                  - If str, the distance metric used to identify the best shapelet.
                  - If list, multiple metrics specified as a list of tuples, where the first
                    element of the tuple is a metric name and the second element a dictionary
                    with a parameter grid specification. A parameter grid specification is a
                    dict with two mandatory and one optional key-value pairs defining the
                    lower and upper bound on the values and number of values in the grid. For
                    example, to specifiy a grid over the argument 'r' with 10 values in the
                    range 0 to 1, we would give the following specification: ``dict(min_r=0,
                    max_r=1, num_r=10)``.

                  Read more about the metrics and their parameters in the
                  :ref:`User guide <list_of_subsequence_metrics>`.
   :type metric: str or list, optional
   :param metric_params: Parameters for the distance measure. Ignored unless metric is a string.

                         Read more about the parameters in the :ref:`User guide
                         <list_of_subsequence_metrics>`.
   :type metric_params: dict, optional
   :param min_shapelet_size: Minimum shapelet size.
   :type min_shapelet_size: float, optional
   :param max_shapelet_size: Maximum shapelet size.
   :type max_shapelet_size: float, optional
   :param n_jobs: The number of jobs to run in parallel. None means 1 and -1 means using all
                  processors.
   :type n_jobs: int, optional
   :param random_state:
                        - If `int`, `random_state` is the seed used by the random number generator
                        - If `RandomState` instance, `random_state` is the random number generator
                        - If `None`, the random number generator is the `RandomState` instance used
                          by `np.random`.
   :type random_state: int or RandomState


.. py:class:: RocketTransform(n_kernels=1000, *, sampling='normal', sampling_params=None, kernel_size=None, min_size=None, max_size=None, bias_prob=1.0, normalize_prob=1.0, padding_prob=0.5, n_jobs=None, random_state=None)

   Bases: :py:obj:`RocketMixin`, :py:obj:`wildboar.transform._base.BaseFeatureEngineerTransform`

   Transform a time series using random convolution features.

   .. attribute:: embedding_

      The underlying embedding

      :type: Embedding

   .. rubric:: References

   Dempster, Angus, Fran√ßois Petitjean, and Geoffrey I. Webb.
       ROCKET: exceptionally fast and accurate time series classification using
       random convolutional kernels.
       Data Mining and Knowledge Discovery 34.5 (2020): 1454-1495.

   Construct a new rocket transform.

   :param n_kernels: The number of kernels to sample at each node.
   :type n_kernels: int, optional
   :param sampling: The sampling of convolutional filters.

                    - if "normal", sample filter according to a normal distribution with
                      ``mean`` and ``scale``.
                    - if "uniform", sample filter according to a uniform distribution with
                      ``lower`` and ``upper``.
                    - if "shapelet", sample filters as subsequences in the training data.
   :type sampling: {"normal", "uniform", "shapelet"}, optional
   :param sampling_params: The parameters for the sampling.

                           - if "normal", ``{"mean": float, "scale": float}``, defaults to
                              ``{"mean": 0, "scale": 1}``.
                           - if "uniform", ``{"lower": float, "upper": float}``, defaults to
                              ``{"lower": -1, "upper": 1}``.
   :type sampling_params: dict, optional
   :param kernel_size: The kernel size, by default ``[7, 11, 13]``.
   :type kernel_size: array-like, optional
   :param min_size: The minimum timestep fraction to generate kernel sizes. If set,
                    ``kernel_size`` cannot be set.
   :type min_size: float, optional
   :param max_size: The maximum timestep fractio to generate kernel sizes, If set,
                    ``kernel_size`` cannot be set.
   :type max_size: float, optional
   :param bias_prob: The probability of using a bias term.
   :type bias_prob: float, optional
   :param normalize_prob: The probability of performing normalization.
   :type normalize_prob: float, optional
   :param padding_prob: The probability of padding with zeros.
   :type padding_prob: float, optional
   :param random_state:
                        - If `int`, `random_state` is the seed used by the random number generator
                        - If `RandomState` instance, `random_state` is the random number generator
                        - If `None`, the random number generator is the `RandomState` instance used
                          by `np.random`.
   :type random_state: int or RandomState


.. py:class:: SAX(*, n_intervals='sqrt', window=None, n_bins=4, binning='normal', estimate=True)

   Bases: :py:obj:`sklearn.base.TransformerMixin`, :py:obj:`wildboar.base.BaseEstimator`

   Symbolic aggregate approximation.

   Construct a new SAX transform.

   :param x: The input data.
   :type x: array-like of shape (n_samples, n_timestep)
   :param n_intervals: The number of intervals to use for the transform.

                       - if "log", the number of intervals is ``log2(n_timestep)``.
                       - if "sqrt", the number of intervals is ``sqrt(n_timestep)``.
                       - if int, the number of intervals is ``n_intervals``.
                       - if float, the number of intervals is ``n_intervals * n_timestep``, with
                           ``0 < n_intervals < 1``.
   :type n_intervals: str, optional
   :param window: The window size. If ``window`` is set, the value of ``n_intervals`` has no
                  effect.
   :type window: int, optional
   :param n_bins: The number of bins.
   :type n_bins: int, optional
   :param binning: The bin construction. By default the bins are defined according to the
                   normal distribution. Possible values are ``"normal"`` for normally
                   distributed bins or ``"uniform"`` for uniformly distributed bins.
   :type binning: str, optional
   :param estimate: Estimate the distribution parameters for the binning from data.

                    If ``estimate=False``, it is assumed that each time series are:

                    - preprocessed using :func:`datasets.preprocess.normalize` when
                      ``binning="normal"``.
                    - preprocessed using :func:`datasets.preprocess.minmax_scale`. when
                      ``binning="uniform"``
   :type estimate: bool, optional

   .. py:property:: intervals


   .. py:method:: fit(x, y=None)


   .. py:method:: inverse_transform(x)


   .. py:method:: transform(x)



.. py:function:: piecewice_aggregate_approximation(x, *, n_intervals='sqrt', window=None)

   Peicewise aggregate approximation.

   :param x: The input data.
   :type x: array-like of shape (n_samples, n_timestep)
   :param n_intervals: The number of intervals to use for the transform.

                       - if "log2", the number of intervals is ``log2(n_timestep)``.
                       - if "sqrt", the number of intervals is ``sqrt(n_timestep)``.
                       - if int, the number of intervals is ``n_intervals``.
                       - if float, the number of intervals is ``n_intervals * n_timestep``, with
                           ``0 < n_intervals < 1``.
   :type n_intervals: str, optional
   :param window: The window size. If ``window`` is set, the value of ``n_intervals`` has no
                  effect.
   :type window: int, optional

   :returns: **paa** -- The symbolic aggregate approximation
   :rtype: ndarray of shape (n_samples, n_intervals)


.. py:function:: symbolic_aggregate_approximation(x, *, n_intervals='sqrt', window=None, n_bins=4, binning='normal')

   Symbolic aggregate approximation.

   :param x: The input data.
   :type x: array-like of shape (n_samples, n_timestep)
   :param n_intervals: The number of intervals to use for the transform.

                       - if "log2", the number of intervals is ``log2(n_timestep)``.
                       - if "sqrt", the number of intervals is ``sqrt(n_timestep)``.
                       - if int, the number of intervals is ``n_intervals``.
                       - if float, the number of intervals is ``n_intervals * n_timestep``, with
                           ``0 < n_intervals < 1``.
   :type n_intervals: str, optional
   :param window: The window size. If ``window`` is set, the value of ``n_intervals`` has no
                  effect.
   :type window: int, optional
   :param n_bins: The number of bins.
   :type n_bins: int, optional
   :param binning: The bin construction. By default the bins are defined according to the
                   normal distribution. Possible values are ``"normal"`` for normally
                   distributed bins or ``"uniform"`` for uniformly distributed bins.
   :type binning: str, optional

   :returns: **sax** -- The symbolic aggregate approximation
   :rtype: ndarray of shape (n_samples, n_intervals)


